[
  {
    "question": "O que é 'Data Skew' em processamento distribuído?",
    "options": [
      "Quando os dados estão uniformemente distribuídos",
      "Quando a maioria dos dados está concentrada em poucas chaves, causando desequilíbrio",
      "Quando os dados são corrompidos durante a transferência",
      "Quando os dados estão encriptados"
    ],
    "answer": 1,
    "category": "Data Engineering",
    "explanation": "'Data Skew' ocorre quando alguns nós processam muito mais dados que outros, levando a um desempenho desigual."
  },
  {
    "question": "Qual algoritmo de Machine Learning é adequado para problemas de classificação binária?",
    "options": [
      "Regressão Linear",
      "Regressão Logística",
      "Análise de Componentes Principais",
      "Clustering K-Means"
    ],
    "answer": 1,
    "category": "Machine Learning",
    "explanation": "A regressão logística é usada para modelar a probabilidade de uma variável dependente binária."
  },
  {
    "question": "Qual é o propósito do 'Slugify' no Airflow?",
    "options": [
      "Converter nomes de DAGs em identificadores válidos",
      "Minimizar o tamanho dos logs",
      "Compactar arquivos de configuração",
      "Não há 'Slugify' no Airflow"
    ],
    "answer": 0,
    "category": "Utilidades",
    "explanation": "O 'Slugify' é usado para gerar identificadores válidos a partir de strings."
  },
  {
    "question": "Qual comando SQL é usado para extrair dados únicos de uma tabela?",
    "options": [
      "SELECT DISTINCT",
      "SELECT UNIQUE",
      "SELECT DIFFERENT",
      "SELECT SINGLE"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "O comando 'SELECT DISTINCT' é usado para retornar apenas valores distintos de uma coluna ou conjunto de colunas em uma tabela."
  },
  {
    "question": "What is the primary purpose of Databricks SQL?",
    "options": [
      "To provide a collaborative environment for data science",
      "To manage and organize data lakes",
      "To analyze data using SQL queries and create visualizations",
      "To train machine learning models"
    ],
    "answer": 2,
    "category": "Databricks SQL",
    "explanation": "Databricks SQL is primarily used for querying data with SQL and creating visualizations."
  },
  {
    "question": "O que significa 'idempotência' no contexto de operações de dados?",
    "options": [
      "Uma operação que falha se repetida",
      "Uma operação que produz o mesmo resultado mesmo se executada várias vezes",
      "Uma operação que sempre retorna valores únicos",
      "Uma operação que depende da ordem de execução"
    ],
    "answer": 1,
    "category": "Data Engineering",
    "explanation": "Uma operação idempotente produz o mesmo resultado independentemente de quantas vezes é executada."
  },
  {
    "question": "Qual método do DataFrame é usado para filtrar linhas com base em uma condição?",
    "options": [
      "filter()",
      "select()",
      "where()",
      "tanto filter() quanto where()"
    ],
    "answer": 3,
    "category": "Dataframes",
    "explanation": "Tanto 'filter()' quanto 'where()' podem ser usados para filtrar linhas com base em uma condição."
  },
  {
    "question": "Qual é o propósito do comando 'REVOKE' no SQL?",
    "options": [
      "Conceder permissões a um usuário",
      "Remover permissões de um usuário",
      "Atualizar dados em uma tabela",
      "Criar um novo banco de dados"
    ],
    "answer": 1,
    "category": "Data Governance",
    "explanation": "O 'REVOKE' é usado para remover permissões previamente concedidas a um usuário ou role."
  },
  {
    "question": "O que é 'DataFrame' no Apache Spark?",
    "options": [
      "Uma coleção distribuída de dados organizada em colunas nomeadas",
      "Um tipo de banco de dados relacional",
      "Um arquivo de configuração do Spark",
      "Uma biblioteca de visualização de dados"
    ],
    "answer": 0,
    "category": "Conceitos do Lakehouse",
    "explanation": "Um DataFrame é uma estrutura de dados do Spark que armazena dados tabulares em colunas nomeadas, similar a uma tabela SQL."
  },
  {
    "question": "O que é uma tabela Delta no contexto do Delta Lake?",
    "options": [
      "Uma tabela armazenada em um banco de dados relacional",
      "Uma tabela que suporta transações ACID e time travel",
      "Uma tabela temporária",
      "Uma tabela somente leitura"
    ],
    "answer": 1,
    "category": "Delta Lake",
    "explanation": "Uma tabela Delta é uma tabela que utiliza o formato Delta Lake, suportando transações ACID, time travel e outras funcionalidades avançadas."
  },
  {
    "question": "Qual cláusula SQL é usada para agrupar resultados que compartilham um valor comum?",
    "options": [
      "GROUP BY",
      "ORDER BY",
      "HAVING",
      "CLUSTER BY"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "A cláusula 'GROUP BY' é usada para agrupar registros que têm valores idênticos em colunas especificadas."
  },
  {
    "question": "Qual operador você usaria para executar uma função Python no Airflow?",
    "options": [
      "BashOperator",
      "PythonOperator",
      "DummyOperator",
      "BranchPythonOperator"
    ],
    "answer": 1,
    "category": "Operadores",
    "explanation": "O PythonOperator permite executar funções Python definidas pelo usuário."
  },
  {
    "question": "Em Machine Learning, o que significa overfitting?",
    "options": [
      "Quando o modelo generaliza bem para dados novos",
      "Quando o modelo é muito simples",
      "Quando o modelo se ajusta muito bem aos dados de treinamento, mas não generaliza para dados novos",
      "Quando o modelo tem baixa variância"
    ],
    "answer": 2,
    "category": "Machine Learning",
    "explanation": "Overfitting ocorre quando um modelo captura o ruído dos dados de treinamento e não funciona bem em dados não vistos."
  },
  {
    "question": "Qual comando exibe a lista de DAGs disponíveis?",
    "options": [
      "airflow list_dags",
      "airflow dags list",
      "airflow show_dags",
      "airflow dag_info"
    ],
    "answer": 0,
    "category": "Comandos",
    "explanation": "O comando 'airflow list_dags' lista todas as DAGs disponíveis."
  },
  {
    "question": "Em Machine Learning, qual é a função da biblioteca MLflow no Databricks?",
    "options": [
      "Gerenciar experimentos de Machine Learning",
      "Fornecer visualizações de dados",
      "Realizar operações ETL",
      "Criar dashboards interativos"
    ],
    "answer": 0,
    "category": "Machine Learning",
    "explanation": "O MLflow é uma plataforma para gerenciar o ciclo de vida de modelos de Machine Learning, incluindo rastreamento de experimentos, projetos e implantação."
  },
  {
    "question": "Qual recurso do Airflow permite escolher dinamicamente qual caminho seguir em uma DAG?",
    "options": [
      "BranchPythonOperator",
      "TriggerDagRunOperator",
      "ShortCircuitOperator",
      "SubDagOperator"
    ],
    "answer": 0,
    "category": "Fluxo Condicional",
    "explanation": "O BranchPythonOperator permite ramificar o fluxo de execução com base em condições."
  },
  {
    "question": "Em que arquivo você configura as conexões do Airflow?",
    "options": [
      "airflow.cfg",
      "connections.yaml",
      "variables.json",
      "No próprio código da DAG"
    ],
    "answer": 0,
    "category": "Configuração",
    "explanation": "As conexões são configuradas no arquivo 'airflow.cfg' ou via interface web."
  },
  {
    "question": "Qual função SQL é usada para calcular a média de um conjunto de valores?",
    "options": [
      "SUM()",
      "COUNT()",
      "AVG()",
      "MAX()"
    ],
    "answer": 2,
    "category": "SQL",
    "explanation": "A função 'AVG()' retorna a média aritmética dos valores em uma coluna."
  },
  {
    "question": "No Databricks, qual recurso permite criar visualizações diretamente de resultados de consultas SQL?",
    "options": [
      "Notebooks",
      "Dashboards",
      "Visualizações Automáticas",
      "Widgets"
    ],
    "answer": 1,
    "category": "Data Visualization",
    "explanation": "Os Dashboards no Databricks permitem criar visualizações a partir de resultados de consultas e compartilhá-los."
  },
  {
    "question": "Qual é a finalidade da função 'DATEDIFF()' no SQL?",
    "options": [
      "Calcular a diferença entre duas datas",
      "Formatar uma data em um determinado padrão",
      "Adicionar dias a uma data",
      "Extrair o dia da semana de uma data"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "A função 'DATEDIFF()' é usada para calcular a diferença entre duas datas especificadas."
  },
  {
    "question": "What type of consistency does Delta Lake offer?",
    "options": [
      "Eventual consistency",
      "Strong consistency",
      "No consistency",
      "Weak consistency"
    ],
    "answer": 1,
    "category": "Delta Lake",
    "explanation": "Delta Lake provides strong consistency, meaning that once a transaction is committed, all subsequent queries will see the result."
  },
  {
    "question": "Qual das seguintes é uma prática recomendada ao criar DAGs?",
    "options": [
      "Definir todas as tarefas dentro de loops",
      "Usar nomes de tarefa dinâmicos baseados em tempo",
      "Manter o número de tarefas gerenciável",
      "Carregar dados diretamente no __init__.py"
    ],
    "answer": 2,
    "category": "Melhores Práticas",
    "explanation": "Manter um número gerenciável de tarefas facilita a manutenção e o monitoramento."
  },
  {
    "question": "O que é 'Data Governance' no contexto de gerenciamento de dados?",
    "options": [
      "Análise de dados para insights",
      "Processo de armazenar dados em um data lake",
      "Conjunto de práticas para garantir a qualidade, segurança e gerenciamento de dados",
      "Execução de consultas em bancos de dados"
    ],
    "answer": 2,
    "category": "Data Governance",
    "explanation": "'Data Governance' refere-se às políticas e procedimentos para gerenciar a disponibilidade, usabilidade, integridade e segurança dos dados."
  },
  {
    "question": "Qual comando Delta Lake é usado para remover arquivos não referenciados antigos para liberar espaço?",
    "options": [
      "DELETE",
      "CLEAN",
      "VACUUM",
      "PURGE"
    ],
    "answer": 2,
    "category": "Delta Lake",
    "explanation": "O comando 'VACUUM' remove arquivos antigos não referenciados para liberar espaço em disco."
  },
  {
    "question": "What does the 'MERGE INTO' command do in Delta Lake?",
    "options": [
      "Updates and inserts data into a table based on conditions",
      "Combines multiple tables into one",
      "Deletes data from multiple tables",
      "Removes duplicates from a table"
    ],
    "answer": 0,
    "category": "Delta Lake",
    "explanation": "The 'MERGE INTO' command allows users to update and insert data into a Delta Lake table based on specified conditions."
  },
  {
    "question": "Qual dos seguintes não é um tipo de operador no Airflow?",
    "options": [
      "EmailOperator",
      "BashOperator",
      "SSHOperator",
      "DataframeOperator"
    ],
    "answer": 3,
    "category": "Operadores",
    "explanation": "Não existe um 'DataframeOperator' nativo no Airflow."
  },
  {
    "question": "O que significa 'XCom' no contexto do Airflow?",
    "options": [
      "Uma ferramenta de comunicação externa",
      "Uma forma de passar mensagens entre tarefas",
      "Um plugin para integração com o XCom server",
      "Uma variável de ambiente"
    ],
    "answer": 1,
    "category": "Comunicação entre Tarefas",
    "explanation": "XCom (Cross-Communication) permite a passagem de pequenas quantidades de dados entre tarefas."
  },
  {
    "question": "Qual é a finalidade do comando 'DROP DATABASE' no SQL?",
    "options": [
      "Remover um banco de dados e todos os seus objetos",
      "Atualizar registros em um banco de dados",
      "Criar um novo banco de dados",
      "Listar todos os bancos de dados"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "O comando 'DROP DATABASE' exclui completamente um banco de dados e todos os seus objetos associados."
  },
  {
    "question": "Qual comando SQL é usado para alterar o nome de uma tabela existente?",
    "options": [
      "ALTER TABLE ... RENAME TO",
      "UPDATE TABLE ... SET NAME",
      "RENAME TABLE ... TO",
      "CHANGE TABLE NAME TO"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "O comando 'ALTER TABLE ... RENAME TO' é usado para renomear uma tabela existente no SQL."
  },
  {
    "question": "Qual é a finalidade do comando 'USE DATABASE' no SQL?",
    "options": [
      "Criar um novo banco de dados",
      "Selecionar um banco de dados para uso",
      "Excluir um banco de dados",
      "Atualizar registros em um banco de dados"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "O comando 'USE DATABASE' seleciona um banco de dados específico para que as operações subsequentes sejam executadas nele."
  },
  {
    "question": "Qual das seguintes opções NÃO é um tipo de join no SQL?",
    "options": [
      "INNER JOIN",
      "OUTER JOIN",
      "CROSS JOIN",
      "UPPER JOIN"
    ],
    "answer": 3,
    "category": "SQL",
    "explanation": "Não existe um 'UPPER JOIN' no SQL; os joins comuns são INNER, OUTER, LEFT, RIGHT e CROSS JOIN."
  },
  {
    "question": "Qual é o papel do 'Command Mode' em um notebook do Databricks?",
    "options": [
      "Executar comandos do sistema operacional",
      "Navegar e editar células do notebook",
      "Compilar código de programação",
      "Visualizar logs de execução"
    ],
    "answer": 1,
    "category": "Databricks Notebooks",
    "explanation": "O 'Command Mode' permite que o usuário navegue entre células e execute operações de edição no notebook."
  },
  {
    "question": "O que é uma 'View' no contexto de bancos de dados SQL?",
    "options": [
      "Uma cópia física de uma tabela",
      "Uma tabela temporária que armazena dados",
      "Uma consulta armazenada que se comporta como uma tabela",
      "Um índice para acelerar consultas"
    ],
    "answer": 2,
    "category": "SQL",
    "explanation": "Uma View é uma consulta armazenada no banco de dados que pode ser tratada como uma tabela virtual."
  },
  {
    "question": "Como você pode compartilhar informações entre tarefas em uma DAG?",
    "options": [
      "Usando arquivos temporários",
      "Através de variáveis de ambiente",
      "Utilizando XComs",
      "Não é possível compartilhar informações"
    ],
    "answer": 2,
    "category": "Comunicação entre Tarefas",
    "explanation": "XComs permitem compartilhar pequenas quantidades de dados entre tarefas."
  },
  {
    "question": "No Databricks, qual é a vantagem de usar 'Tables ACID'?",
    "options": [
      "Melhora a compressão de dados",
      "Suporta transações com propriedades ACID",
      "Facilita a criação de visualizações",
      "Permite consultas em linguagem natural"
    ],
    "answer": 1,
    "category": "Delta Lake",
    "explanation": "Tabelas ACID garantem Atomicidade, Consistência, Isolamento e Durabilidade nas transações de dados."
  },
  {
    "question": "Qual biblioteca é usada pelo Airflow para criar a interface web?",
    "options": [
      "Django",
      "Flask",
      "Pyramid",
      "Bottle"
    ],
    "answer": 1,
    "category": "Tecnologias",
    "explanation": "O Airflow usa o Flask para sua interface web."
  },
  {
    "question": "No Databricks, o que são 'Global Temp Views'?",
    "options": [
      "Visualizações temporárias disponíveis apenas para a sessão atual",
      "Visualizações temporárias compartilhadas entre todas as sessões e clusters",
      "Tabelas permanentes armazenadas no sistema",
      "Visualizações usadas apenas para visualização de dados"
    ],
    "answer": 1,
    "category": "Databricks SQL",
    "explanation": "'Global Temp Views' são visualizações temporárias que podem ser acessadas por diferentes sessões e clusters."
  },
  {
    "question": "Qual métrica é adequada para avaliar modelos de regressão?",
    "options": [
      "Acurácia",
      "Matriz de confusão",
      "Erro Quadrático Médio (MSE)",
      "Coeficiente de Gini"
    ],
    "answer": 2,
    "category": "Machine Learning",
    "explanation": "O MSE mede a média dos quadrados dos erros e é apropriado para avaliar modelos de regressão."
  },
  {
    "question": "No contexto de visualização de dados, para que é usado um gráfico de linhas?",
    "options": [
      "Comparar categorias distintas",
      "Mostrar a distribuição de uma variável",
      "Representar tendências ao longo do tempo",
      "Analisar a relação entre duas variáveis numéricas"
    ],
    "answer": 2,
    "category": "Visualização de Dados",
    "explanation": "Gráficos de linhas são ideais para mostrar como os valores de uma variável mudam ao longo do tempo."
  },
  {
    "question": "Which feature allows Databricks users to track and manage machine learning models?",
    "options": [
      "SQL Analytics",
      "MLflow",
      "Delta Live Tables",
      "Spark SQL"
    ],
    "answer": 1,
    "category": "Machine Learning",
    "explanation": "MLflow is a tool in Databricks that allows users to track, manage, and deploy machine learning models."
  },
  {
    "question": "Qual função SQL retorna o número de registros em um grupo?",
    "options": [
      "COUNT()",
      "SUM()",
      "TOTAL()",
      "NUMBER()"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "A função 'COUNT()' retorna o número de registros correspondentes a uma condição."
  },
  {
    "question": "O que o parâmetro 'retry_delay' especifica em uma tarefa do Airflow?",
    "options": [
      "O tempo máximo para executar a tarefa",
      "O tempo entre tentativas em caso de falha",
      "A frequência de agendamento da tarefa",
      "O atraso inicial antes da primeira execução"
    ],
    "answer": 1,
    "category": "Configuração de Tarefas",
    "explanation": "O 'retry_delay' define o tempo de espera entre tentativas após uma falha."
  },
  {
    "question": "Qual é a principal vantagem de usar o Delta Lake em comparação com o Apache Parquet?",
    "options": [
      "Compatibilidade com todos os sistemas de arquivos",
      "Transações ACID",
      "Maior velocidade de leitura",
      "Menor uso de armazenamento"
    ],
    "answer": 1,
    "category": "Delta Lake",
    "explanation": "O Delta Lake adiciona transações ACID aos dados em um Data Lake, permitindo operações confiáveis de leitura e escrita."
  },
  {
    "question": "No Databricks, o que é 'Unity Catalog'?",
    "options": [
      "Um catálogo unificado de dados para governança",
      "Um serviço de armazenamento em nuvem",
      "Uma ferramenta de visualização",
      "Um editor de código"
    ],
    "answer": 0,
    "category": "Data Governance",
    "explanation": "O 'Unity Catalog' é um serviço de governança que oferece gerenciamento centralizado de metadados e permissões."
  },
  {
    "question": "No contexto de visualização de dados, o que é um 'Heatmap'?",
    "options": [
      "Um gráfico que mostra a distribuição de dados geográficos",
      "Uma representação gráfica que usa cores para mostrar a magnitude dos valores",
      "Um gráfico que conecta pontos de dados em uma linha",
      "Um tipo de gráfico de barras vertical"
    ],
    "answer": 1,
    "category": "Visualização de Dados",
    "explanation": "Um 'Heatmap' usa cores para representar a magnitude dos valores em uma matriz bidimensional."
  },
  {
    "question": "Qual componente do Airflow define a estrutura dos fluxos de trabalho?",
    "options": [
      "Operadores",
      "DAGs",
      "Conexões",
      "Variáveis"
    ],
    "answer": 1,
    "category": "Conceitos Básicos",
    "explanation": "As DAGs (Directed Acyclic Graphs) definem a estrutura e a ordem dos fluxos de trabalho no Airflow."
  },
  {
    "question": "No contexto do Spark, o que é uma 'Action'?",
    "options": [
      "Uma operação que retorna um valor ao driver",
      "Uma transformação de dados",
      "Um método para definir esquemas",
      "Uma ferramenta de visualização"
    ],
    "answer": 0,
    "category": "Apache Spark",
    "explanation": "Uma 'Action' é uma operação que força a computação e retorna um resultado ao programa do driver."
  },
  {
    "question": "O que é 'DagRun' no Airflow?",
    "options": [
      "Uma instância de execução de uma DAG",
      "Uma tarefa individual dentro de uma DAG",
      "O processo de agendamento do Airflow",
      "Um plugin para integração com Hadoop"
    ],
    "answer": 0,
    "category": "Conceitos Básicos",
    "explanation": "Um 'DagRun' representa uma execução específica de uma DAG."
  },
  {
    "question": "Qual recurso permite que o Airflow gerencie dependências entre DAGs diferentes?",
    "options": [
      "ExternalTaskSensor",
      "CrossDagOperator",
      "InterDagDependency",
      "GlobalVariables"
    ],
    "answer": 0,
    "category": "Dependências",
    "explanation": "O 'ExternalTaskSensor' permite que uma DAG espere por tarefas em outra DAG."
  },
  {
    "question": "Qual comando SQL é usado para conceder todas as permissões em um objeto a um usuário?",
    "options": [
      "GRANT ALL PRIVILEGES ON objeto TO usuário",
      "GRANT FULL ACCESS ON objeto TO usuário",
      "GRANT PERMISSIONS ON objeto TO usuário",
      "GRANT ACCESS ON objeto TO usuário"
    ],
    "answer": 0,
    "category": "Data Governance",
    "explanation": "O comando 'GRANT ALL PRIVILEGES ON objeto TO usuário' concede todas as permissões disponíveis no objeto especificado."
  },
  {
    "question": "Em qual linguagem de programação as DAGs do Airflow são escritas?",
    "options": [
      "Java",
      "Python",
      "Scala",
      "Ruby"
    ],
    "answer": 1,
    "category": "Desenvolvimento",
    "explanation": "As DAGs do Airflow são definidas usando scripts Python."
  },
  {
    "question": "Qual é o padrão de design principal que o Airflow segue?",
    "options": [
      "Fluxo de Dados",
      "Programação Declarativa",
      "Programação Funcional",
      "Fluxo de Trabalho como Código"
    ],
    "answer": 3,
    "category": "Conceitos Básicos",
    "explanation": "O Airflow implementa o conceito de 'Fluxo de Trabalho como Código' usando Python."
  },
  {
    "question": "Qual é a finalidade da função 'COALESCE()' no SQL?",
    "options": [
      "Combinar várias colunas em uma",
      "Substituir valores nulos por um valor especificado",
      "Dividir uma coluna em várias",
      "Contar o número de valores não nulos"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "A função 'COALESCE()' retorna o primeiro valor não nulo em uma lista de argumentos."
  },
  {
    "question": "Qual backend de metadados NÃO é suportado pelo Airflow?",
    "options": [
      "MySQL",
      "PostgreSQL",
      "SQLite",
      "MongoDB"
    ],
    "answer": 3,
    "category": "Configuração",
    "explanation": "O Airflow não suporta MongoDB como backend de metadados."
  },
  {
    "question": "Qual serviço do Airflow é responsável por agendar as tarefas?",
    "options": [
      "Executor",
      "Scheduler",
      "Webserver",
      "Worker"
    ],
    "answer": 1,
    "category": "Arquitetura",
    "explanation": "O Scheduler é responsável por agendar as tarefas conforme definido nas DAGs."
  },
  {
    "question": "What is a benefit of using Delta Live Tables in Databricks?",
    "options": [
      "Simplifies real-time analytics pipelines",
      "Provides machine learning libraries",
      "Enhances job scheduling",
      "Supports external database integration"
    ],
    "answer": 0,
    "category": "Real-Time Processing",
    "explanation": "Delta Live Tables simplifies the development of real-time data pipelines by automating operations such as data ingestion and processing."
  },
  {
    "question": "Qual função SQL retorna o maior valor de uma coluna numérica?",
    "options": [
      "SUM()",
      "COUNT()",
      "MIN()",
      "MAX()"
    ],
    "answer": 3,
    "category": "SQL",
    "explanation": "A função 'MAX()' retorna o maior valor encontrado em uma coluna específica."
  },
  {
    "question": "O que é 'Delta Engine' no contexto do Databricks?",
    "options": [
      "Um mecanismo de armazenamento de dados",
      "Uma biblioteca de Machine Learning",
      "Um mecanismo de processamento otimizado para Delta Lake",
      "Uma ferramenta de visualização de dados"
    ],
    "answer": 2,
    "category": "Delta Lake",
    "explanation": "O 'Delta Engine' é um mecanismo de processamento de consultas de alto desempenho otimizado para trabalhar com o Delta Lake."
  },
  {
    "question": "What is the role of Databricks Auto Scaling?",
    "options": [
      "Adjusting cluster size based on workload",
      "Preventing all downtime",
      "Only scaling up clusters",
      "Requires manual adjustments"
    ],
    "answer": 0,
    "category": "Cluster Management",
    "explanation": "Databricks Auto Scaling automatically adjusts the size of a cluster based on the workload to optimize resource usage."
  },
  {
    "question": "What does the 'OPTIMIZE' command do in Delta Lake?",
    "options": [
      "Increases query performance by organizing data files",
      "Deletes old versions of data",
      "Adds new data to a table",
      "Reverts to previous table versions"
    ],
    "answer": 0,
    "category": "Delta Lake",
    "explanation": "The 'OPTIMIZE' command improves query performance by compacting small data files into larger, more efficient ones."
  },
  {
    "question": "O que é 'Schema Evolution' no Delta Lake?",
    "options": [
      "A capacidade de alterar o esquema de dados ao longo do tempo",
      "Uma técnica de otimização de consultas",
      "Um método de particionamento de dados",
      "Uma ferramenta de segurança de dados"
    ],
    "answer": 0,
    "category": "Delta Lake",
    "explanation": "O 'Schema Evolution' permite que o esquema de uma tabela Delta seja alterado automaticamente para acomodar novos dados."
  },
  {
    "question": "Qual comando SQL é usado para inserir novos registros em uma tabela?",
    "options": [
      "INSERT INTO",
      "UPDATE",
      "ADD RECORD",
      "APPEND"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "O comando 'INSERT INTO' é usado para inserir novos registros em uma tabela existente."
  },
  {
    "question": "Qual é a finalidade do 'SubDagOperator'?",
    "options": [
      "Dividir uma DAG em sub-DAGs para melhor organização",
      "Executar DAGs em ambientes de teste",
      "Agendar DAGs em servidores diferentes",
      "Conectar múltiplas DAGs independentes"
    ],
    "answer": 0,
    "category": "Organização",
    "explanation": "O 'SubDagOperator' permite encapsular tarefas dentro de uma sub-DAG para melhor organização."
  },
  {
    "question": "Qual comando SQL é usado para inserir novos dados em uma tabela?",
    "options": [
      "INSERT INTO",
      "ADD DATA",
      "UPDATE TABLE",
      "APPEND ROW"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "O comando 'INSERT INTO' é usado para adicionar novos registros a uma tabela existente."
  },
  {
    "question": "Como você define uma dependência de tarefa no Airflow?",
    "options": [
      "Usando set_upstream e set_downstream",
      "Alterando a ordem das tarefas no código",
      "Através do arquivo de configuração",
      "Não é possível definir dependências"
    ],
    "answer": 0,
    "category": "Dependências",
    "explanation": "As dependências são definidas usando os métodos set_upstream e set_downstream."
  },
  {
    "question": "Which of the following is a feature of Databricks notebooks?",
    "options": [
      "Support for multiple languages",
      "Version control integration",
      "Real-time collaboration",
      "All of the above"
    ],
    "answer": 3,
    "category": "Databricks Notebooks",
    "explanation": "Databricks notebooks support multiple languages, real-time collaboration, and integration with version control systems."
  },
  {
    "question": "No contexto do Spark, o que é um 'Resilient Distributed Dataset' (RDD)?",
    "options": [
      "Uma coleção imutável de objetos distribuídos",
      "Um tipo de banco de dados relacional",
      "Uma função para processamento de streams",
      "Um mecanismo de armazenamento em cache"
    ],
    "answer": 0,
    "category": "Apache Spark",
    "explanation": "Um RDD é uma coleção distribuída e imutável de objetos que podem ser processados em paralelo."
  },
  {
    "question": "Qual técnica de Machine Learning é usada para reduzir a dimensionalidade dos dados?",
    "options": [
      "Regressão Linear",
      "Análise de Componentes Principais (PCA)",
      "Árvores de Decisão",
      "K-Means Clustering"
    ],
    "answer": 1,
    "category": "Machine Learning",
    "explanation": "O PCA é uma técnica que transforma dados de alta dimensionalidade em um conjunto menor de variáveis, preservando a maior parte da variabilidade."
  },
  {
    "question": "O que é um 'Managed Table' no Databricks?",
    "options": [
      "Uma tabela cujos dados são gerenciados pelo sistema",
      "Uma tabela externa",
      "Uma tabela temporária",
      "Uma tabela que existe apenas em memória"
    ],
    "answer": 0,
    "category": "Databricks SQL",
    "explanation": "Em uma 'Managed Table', o Databricks gerencia tanto os metadados quanto os dados da tabela."
  },
  {
    "question": "Qual é a finalidade da cláusula 'HAVING' no SQL?",
    "options": [
      "Filtrar resultados após uma agregação",
      "Ordenar os resultados",
      "Limitar o número de resultados",
      "Agrupar registros com valores idênticos"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "A cláusula 'HAVING' é usada para filtrar resultados após uma operação de agregação com 'GROUP BY'."
  },
  {
    "question": "Qual componente do MLflow é usado para armazenar versões de modelos treinados?",
    "options": [
      "MLflow Tracking",
      "MLflow Projects",
      "MLflow Models",
      "MLflow Registry"
    ],
    "answer": 3,
    "category": "Machine Learning",
    "explanation": "O 'MLflow Registry' é usado para gerenciar o ciclo de vida de modelos, incluindo versionamento e implantação."
  },
  {
    "question": "No Databricks, qual recurso permite o processamento em tempo real de dados de streaming?",
    "options": [
      "Delta Engine",
      "Structured Streaming",
      "Auto Loader",
      "Time Travel"
    ],
    "answer": 1,
    "category": "Streaming",
    "explanation": "O Structured Streaming é a API do Spark para processar fluxos de dados em tempo real no Databricks."
  },
  {
    "question": "Qual é a finalidade do comando 'EXPLAIN' no SQL?",
    "options": [
      "Executar uma consulta",
      "Fornecer o plano de execução de uma consulta",
      "Atualizar dados em uma tabela",
      "Criar uma nova tabela"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "O comando 'EXPLAIN' mostra o plano de execução que o banco de dados usará para executar uma consulta."
  },
  {
    "question": "No Databricks, qual é o propósito do 'Cluster Manager'?",
    "options": [
      "Gerenciar recursos computacionais",
      "Criar visualizações de dados",
      "Escrever código SQL",
      "Armazenar dados em tabelas"
    ],
    "answer": 0,
    "category": "Conceitos do Lakehouse",
    "explanation": "O 'Cluster Manager' é responsável por gerenciar a criação e operação de clusters de computação."
  },
  {
    "question": "Which tool in Databricks helps to monitor the performance and execution of jobs?",
    "options": [
      "Job UI",
      "Structured Streaming",
      "Spark UI",
      "MLflow"
    ],
    "answer": 2,
    "category": "Monitoring",
    "explanation": "The Spark UI allows you to monitor the execution of Spark jobs and diagnose performance issues."
  },
  {
    "question": "Qual é a finalidade do comando 'CREATE DATABASE' no SQL?",
    "options": [
      "Atualizar registros em uma tabela",
      "Criar um novo banco de dados",
      "Excluir um banco de dados existente",
      "Adicionar uma nova coluna a uma tabela"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "O comando 'CREATE DATABASE' é usado para criar um novo banco de dados no sistema."
  },
  {
    "question": "O que significa 'idempotência' no contexto de tarefas do Airflow?",
    "options": [
      "Executar múltiplas vezes sem efeitos colaterais adicionais",
      "Capacidade de executar em múltiplos servidores",
      "Execução paralela de tarefas",
      "Dependência circular entre tarefas"
    ],
    "answer": 0,
    "category": "Melhores Práticas",
    "explanation": "Tarefas idempotentes podem ser executadas várias vezes sem alterar o resultado além da primeira execução."
  },
  {
    "question": "Qual método do DataFrame é usado para agrupar dados com base em uma ou mais colunas?",
    "options": [
      "groupBy()",
      "aggregate()",
      "collect()",
      "partitionBy()"
    ],
    "answer": 0,
    "category": "Dataframes",
    "explanation": "O método 'groupBy()' é usado para agrupar dados e permite aplicar funções de agregação."
  },
  {
    "question": "O que é 'Caching' no contexto do Spark?",
    "options": [
      "Armazenar dados em memória para acesso rápido",
      "Excluir dados não utilizados",
      "Compactar arquivos de dados",
      "Dividir dados em partições"
    ],
    "answer": 0,
    "category": "Conceitos do Lakehouse",
    "explanation": "O 'Caching' armazena dados frequentemente acessados em memória para melhorar o desempenho das consultas."
  },
  {
    "question": "Qual comando SQL é usado para modificar registros existentes em uma tabela?",
    "options": [
      "ALTER",
      "UPDATE",
      "MODIFY",
      "CHANGE"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "O comando 'UPDATE' é usado para modificar os dados existentes em uma tabela."
  },
  {
    "question": "Which Databricks feature helps to optimize queries for faster performance?",
    "options": [
      "Databricks Photon",
      "MLflow",
      "Delta Live Tables",
      "SQL Analytics"
    ],
    "answer": 0,
    "category": "Optimization",
    "explanation": "Databricks Photon is a vectorized engine that optimizes query execution for faster performance."
  },
  {
    "question": "Qual é a função do comando 'DESCRIBE TABLE' no SQL?",
    "options": [
      "Inserir dados em uma tabela",
      "Mostrar a estrutura de uma tabela",
      "Excluir uma tabela",
      "Atualizar registros em uma tabela"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "O comando 'DESCRIBE TABLE' é usado para exibir a estrutura e os detalhes de uma tabela, como colunas e tipos de dados."
  },
  {
    "question": "Qual comando SQL é usado para remover registros duplicados de um resultado de consulta?",
    "options": [
      "DELETE DUPLICATES",
      "DISTINCT",
      "REMOVE DUPLICATE",
      "UNIQUE"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "O uso de 'SELECT DISTINCT' retorna apenas registros únicos, eliminando duplicatas."
  },
  {
    "question": "No contexto do Databricks, o que é o 'Databricks Runtime'?",
    "options": [
      "Um sistema operacional personalizado",
      "Uma distribuição otimizada do Apache Spark",
      "Uma linguagem de programação proprietária",
      "Um banco de dados relacional"
    ],
    "answer": 1,
    "category": "Conceitos do Lakehouse",
    "explanation": "O Databricks Runtime é uma distribuição otimizada do Apache Spark que inclui melhorias de desempenho e funcionalidades adicionais."
  },
  {
    "question": "O que é 'Spark SQL' no contexto do Databricks?",
    "options": [
      "Uma interface para interagir com o Spark usando SQL",
      "Um banco de dados interno do Spark",
      "Uma ferramenta para visualização de dados",
      "Um módulo de Machine Learning"
    ],
    "answer": 0,
    "category": "Databricks SQL",
    "explanation": "O Spark SQL permite que os usuários executem consultas SQL sobre dados armazenados no Apache Spark."
  },
  {
    "question": "Qual biblioteca é comumente usada no Databricks para criar visualizações de dados interativas?",
    "options": [
      "matplotlib",
      "pandas",
      "plotly",
      "numpy"
    ],
    "answer": 2,
    "category": "Data Visualization",
    "explanation": "A biblioteca 'plotly' permite criar visualizações interativas e é suportada pelo Databricks."
  },
  {
    "question": "O que é 'Structured Streaming' no Spark?",
    "options": [
      "Uma API para processamento de fluxos de dados em tempo real",
      "Uma ferramenta de agendamento de tarefas",
      "Um módulo para análise de dados estruturados",
      "Uma biblioteca de visualização"
    ],
    "answer": 0,
    "category": "Streaming",
    "explanation": "O 'Structured Streaming' é uma API que permite o processamento de fluxos de dados de forma contínua e escalável."
  },
  {
    "question": "Qual comando SQL é usado para combinar registros de duas tabelas baseadas em uma coluna relacionada?",
    "options": [
      "UNION",
      "JOIN",
      "INTERSECT",
      "MERGE"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "O 'JOIN' combina registros de duas tabelas com base em uma coluna compartilhada ou relacionada."
  },
  {
    "question": "No Spark DataFrame API, qual método é usado para selecionar colunas específicas?",
    "options": [
      "select()",
      "filter()",
      "groupBy()",
      "orderBy()"
    ],
    "answer": 0,
    "category": "Dataframes",
    "explanation": "O método 'select()' é usado para projetar um DataFrame selecionando colunas específicas."
  },
  {
    "question": "Qual é a finalidade do comando 'CREATE VIEW' no SQL?",
    "options": [
      "Criar uma nova tabela",
      "Atualizar uma tabela existente",
      "Criar uma visão virtual de uma consulta",
      "Excluir uma visão existente"
    ],
    "answer": 2,
    "category": "SQL",
    "explanation": "O 'CREATE VIEW' cria uma visão virtual baseada em uma consulta SQL, que pode ser usada como uma tabela."
  },
  {
    "question": "Qual tipo de gráfico é mais apropriado para mostrar a distribuição de uma variável contínua?",
    "options": [
      "Gráfico de barras",
      "Histograma",
      "Gráfico de pizza",
      "Gráfico de linhas"
    ],
    "answer": 1,
    "category": "Data Visualization",
    "explanation": "Um histograma é usado para representar a distribuição de uma variável contínua dividindo os dados em intervalos."
  },
  {
    "question": "Qual é a diferença entre 'INNER JOIN' e 'LEFT JOIN' no SQL?",
    "options": [
      "'INNER JOIN' retorna todas as linhas, 'LEFT JOIN' retorna apenas correspondências",
      "'INNER JOIN' retorna correspondências exatas, 'LEFT JOIN' inclui todas as linhas da tabela da esquerda",
      "'LEFT JOIN' retorna correspondências exatas, 'INNER JOIN' inclui todas as linhas da tabela da esquerda",
      "'LEFT JOIN' não existe no SQL"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "'INNER JOIN' retorna apenas as linhas com correspondências em ambas as tabelas, enquanto 'LEFT JOIN' retorna todas as linhas da tabela da esquerda, incluindo as não correspondidas."
  },
  {
    "question": "Qual comando inicia a interface web do Airflow?",
    "options": [
      "airflow scheduler",
      "airflow webserver",
      "airflow initdb",
      "airflow run"
    ],
    "answer": 1,
    "category": "Comandos",
    "explanation": "O comando 'airflow webserver' inicia a interface web do Airflow."
  },
  {
    "question": "Qual método do DataFrame é usado para adicionar uma nova coluna calculada?",
    "options": [
      "withColumn()",
      "addColumn()",
      "insertColumn()",
      "createColumn()"
    ],
    "answer": 0,
    "category": "Dataframes",
    "explanation": "O método 'withColumn()' cria uma nova coluna ou substitui uma existente com base em uma expressão especificada."
  },
  {
    "question": "Qual função Spark SQL é usada para calcular a média de valores em uma coluna numérica?",
    "options": [
      "AVG()",
      "SUM()",
      "COUNT()",
      "MAX()"
    ],
    "answer": 0,
    "category": "Spark SQL",
    "explanation": "A função 'AVG()' calcula a média aritmética dos valores em uma coluna numérica."
  },
  {
    "question": "Qual é a finalidade do comando 'DELETE FROM' no SQL?",
    "options": [
      "Remover uma tabela",
      "Excluir registros específicos de uma tabela",
      "Limpar todos os dados de uma tabela",
      "Excluir um banco de dados inteiro"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "O 'DELETE FROM' remove registros específicos de uma tabela com base em uma condição."
  },
  {
    "question": "No Databricks, o que é 'Photon'?",
    "options": [
      "Um acelerador de consultas SQL de alto desempenho",
      "Uma linguagem de programação",
      "Um sistema de armazenamento de dados",
      "Um serviço de aprendizado de máquina"
    ],
    "answer": 0,
    "category": "Databricks SQL",
    "explanation": "O 'Photon' é um mecanismo nativo de execução de consultas SQL que oferece alto desempenho no Databricks."
  },
  {
    "question": "Qual é a finalidade do 'Sensor' no Airflow?",
    "options": [
      "Enviar notificações por e-mail",
      "Esperar por uma condição específica antes de prosseguir",
      "Executar tarefas de limpeza",
      "Monitorar o desempenho do sistema"
    ],
    "answer": 1,
    "category": "Operadores",
    "explanation": "Sensores são usados para esperar até que uma condição específica seja atendida."
  },
  {
    "question": "Qual das seguintes opções permite a integração do Airflow com o Kubernetes?",
    "options": [
      "KubernetesExecutor",
      "CeleryExecutor",
      "LocalExecutor",
      "DaskExecutor"
    ],
    "answer": 0,
    "category": "Executores",
    "explanation": "O KubernetesExecutor permite que tarefas sejam executadas em pods no Kubernetes."
  },
  {
    "question": "O que é 'Cluster Auto-Scaling' no Databricks?",
    "options": [
      "A capacidade de ajustar automaticamente o tamanho do cluster com base na carga de trabalho",
      "Um método de segurança de clusters",
      "Uma ferramenta para criar visualizações",
      "Um serviço para armazenar dados"
    ],
    "answer": 0,
    "category": "Conceitos do Lakehouse",
    "explanation": "'Cluster Auto-Scaling' permite que o Databricks aumente ou diminua automaticamente os recursos do cluster conforme necessário."
  },
  {
    "question": "Qual é o papel do 'Cluster Mode' no Databricks?",
    "options": [
      "Determinar a interface do usuário",
      "Definir como o driver e os executores são alocados",
      "Especificar o sistema operacional",
      "Configurar a segurança do cluster"
    ],
    "answer": 1,
    "category": "Conceitos do Lakehouse",
    "explanation": "O 'Cluster Mode' determina a distribuição do driver e dos executores em um cluster de computação."
  },
  {
    "question": "Qual cláusula SQL é usada para ordenar o resultado de uma consulta?",
    "options": [
      "ORDER BY",
      "GROUP BY",
      "SORT",
      "ARRANGE BY"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "A cláusula 'ORDER BY' é usada para ordenar os registros em ordem crescente ou decrescente."
  },
  {
    "question": "Which of the following Databricks features enables real-time stream processing?",
    "options": [
      "Delta Lake",
      "Spark SQL",
      "Structured Streaming",
      "Databricks Jobs"
    ],
    "answer": 2,
    "category": "Real-Time Processing",
    "explanation": "Structured Streaming allows real-time processing of data streams in Databricks."
  },
  {
    "question": "Which of the following statements is true about Delta Lake's schema enforcement?",
    "options": [
      "It prevents invalid data from being written",
      "It allows any data format",
      "It enforces schema only at the database level",
      "It cannot be modified after table creation"
    ],
    "answer": 0,
    "category": "Delta Lake",
    "explanation": "Schema enforcement in Delta Lake ensures that only data that matches the table's schema can be written to the table."
  },
  {
    "question": "Qual comando SQL é usado para criar um índice em uma tabela?",
    "options": [
      "CREATE INDEX",
      "ADD INDEX",
      "GENERATE INDEX",
      "MAKE INDEX"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "O comando 'CREATE INDEX' é usado para criar um índice em uma ou mais colunas de uma tabela."
  },
  {
    "question": "No contexto do Databricks, o que é um 'Workspace'?",
    "options": [
      "Um ambiente colaborativo para projetos",
      "Uma máquina virtual individual",
      "Um tipo de cluster de computação",
      "Uma biblioteca de funções pré-construídas"
    ],
    "answer": 0,
    "category": "Conceitos do Lakehouse",
    "explanation": "Um 'Workspace' é um ambiente onde usuários podem colaborar em notebooks, trabalhos e outros recursos."
  },
  {
    "question": "O que é 'Data Lineage' em Data Governance?",
    "options": [
      "O histórico de origens e transformações dos dados",
      "A qualidade dos dados em um sistema",
      "A segurança aplicada aos dados",
      "A estrutura de armazenamento dos dados"
    ],
    "answer": 0,
    "category": "Data Governance",
    "explanation": "'Data Lineage' refere-se ao rastreamento da origem dos dados e todas as transformações que eles sofreram."
  },
  {
    "question": "Qual comando é usado para inicializar o banco de dados de metadados do Airflow?",
    "options": [
      "airflow db init",
      "airflow initdb",
      "airflow createdb",
      "airflow startdb"
    ],
    "answer": 1,
    "category": "Comandos",
    "explanation": "O comando 'airflow initdb' inicializa o banco de dados de metadados."
  },
  {
    "question": "Qual comando é usado para executar time travel no Delta Lake?",
    "options": [
      "SELECT * FROM tabela TIMESTAMP AS OF data",
      "SELECT * FROM tabela VERSION AS OF número",
      "Ambos os anteriores",
      "Nenhum dos anteriores"
    ],
    "answer": 2,
    "category": "Delta Lake",
    "explanation": "No Delta Lake, você pode usar 'TIMESTAMP AS OF' ou 'VERSION AS OF' para consultar versões anteriores dos dados."
  },
  {
    "question": "O que é um 'Hook' no Airflow?",
    "options": [
      "Uma extensão para adicionar novos operadores",
      "Uma interface para se conectar a serviços externos",
      "Uma função de callback após a execução da tarefa",
      "Um mecanismo para agendar DAGs"
    ],
    "answer": 1,
    "category": "Integrações",
    "explanation": "Hooks são interfaces que facilitam a conexão com serviços externos, como bancos de dados."
  },
  {
    "question": "Which of the following is a key feature of Delta Lake?",
    "options": [
      "Versioning",
      "Batch processing only",
      "Machine learning support",
      "No schema enforcement"
    ],
    "answer": 0,
    "category": "Delta Lake",
    "explanation": "Delta Lake's versioning feature allows you to track and manage multiple versions of data over time."
  },
  {
    "question": "Qual é a finalidade do comando 'TRUNCATE TABLE' no SQL?",
    "options": [
      "Excluir uma tabela",
      "Remover todas as linhas de uma tabela",
      "Atualizar registros específicos",
      "Reduzir o tamanho físico da tabela"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "O 'TRUNCATE TABLE' remove todas as linhas de uma tabela de forma eficiente, mas mantém sua estrutura."
  },
  {
    "question": "O que é um 'External Table' no contexto do SQL?",
    "options": [
      "Uma tabela armazenada fora do banco de dados",
      "Uma visão temporária de dados",
      "Uma tabela que referencia dados externos sem importá-los",
      "Uma tabela que existe apenas durante a sessão atual"
    ],
    "answer": 2,
    "category": "Databricks SQL",
    "explanation": "Uma 'External Table' referencia dados armazenados fora do banco de dados, permitindo consultas sem importação."
  },
  {
    "question": "Como você pode monitorar tarefas no Airflow?",
    "options": [
      "Apenas através de logs de sistema",
      "Usando a interface web do Airflow",
      "Não é possível monitorar tarefas",
      "Somente via linha de comando"
    ],
    "answer": 1,
    "category": "Monitoramento",
    "explanation": "A interface web do Airflow fornece ferramentas para monitorar tarefas e DAGs."
  },
  {
    "question": "No Databricks, qual recurso permite versionar código dentro de notebooks?",
    "options": [
      "Notebook Revisions",
      "Git Integration",
      "Cluster Snapshots",
      "Version Control System"
    ],
    "answer": 1,
    "category": "Conceitos do Lakehouse",
    "explanation": "A integração com Git permite versionar e controlar o código dentro dos notebooks do Databricks."
  },
  {
    "question": "Qual operador você usaria para executar uma consulta SQL no Airflow?",
    "options": [
      "BashOperator",
      "PythonOperator",
      "SqlOperator",
      "EmailOperator"
    ],
    "answer": 2,
    "category": "Operadores",
    "explanation": "O SqlOperator é usado para executar consultas SQL em bancos de dados."
  },
  {
    "question": "Qual função SQL é usada para arredondar um número para um número específico de decimais?",
    "options": [
      "ROUND()",
      "FLOOR()",
      "CEIL()",
      "TRUNC()"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "A função 'ROUND()' é usada para arredondar um número para um número especificado de casas decimais."
  },
  {
    "question": "O que é o 'Auto Loader' no contexto do Databricks?",
    "options": [
      "Uma ferramenta para carregar dados manualmente",
      "Um serviço para automatizar a ingestão de dados",
      "Um recurso para limpar dados duplicados",
      "Um módulo de Machine Learning"
    ],
    "answer": 1,
    "category": "Ingestão de Dados",
    "explanation": "O Auto Loader é um recurso que automatiza a ingestão contínua de dados em tabelas Delta."
  },
  {
    "question": "Qual cláusula SQL é usada para filtrar registros em uma consulta com base em uma condição?",
    "options": [
      "WHERE",
      "HAVING",
      "GROUP BY",
      "ORDER BY"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "A cláusula 'WHERE' é usada para filtrar registros que atendem a uma condição especificada."
  },
  {
    "question": "No Databricks, o que é 'Parquet'?",
    "options": [
      "Um formato de arquivo colunares otimizado",
      "Uma linguagem de programação",
      "Um tipo de cluster",
      "Uma ferramenta de visualização de dados"
    ],
    "answer": 0,
    "category": "Conceitos do Lakehouse",
    "explanation": "'Parquet' é um formato de arquivo colunares que é eficiente para armazenamento e processamento de dados analíticos."
  },
  {
    "question": "No contexto do Apache Spark, o que é 'Broadcast Join'?",
    "options": [
      "Um join que replica uma pequena tabela para todos os nós",
      "Um join que distribui dados igualmente entre nós",
      "Um join que só funciona com dados de streaming",
      "Um join que ignora dados duplicados"
    ],
    "answer": 0,
    "category": "Apache Spark",
    "explanation": "'Broadcast Join' é uma técnica onde uma pequena tabela é enviada para todos os nós para otimizar o join com uma tabela grande."
  },
  {
    "question": "Which of the following is a benefit of Delta Lake's time travel feature?",
    "options": [
      "Viewing older versions of data",
      "Faster query execution",
      "Schema enforcement",
      "Support for machine learning"
    ],
    "answer": 0,
    "category": "Delta Lake",
    "explanation": "Time travel allows users to access previous versions of data for auditing or recovery."
  },
  {
    "question": "What is the default file format used by Delta Lake?",
    "options": [
      "Parquet",
      "CSV",
      "JSON",
      "ORC"
    ],
    "answer": 0,
    "category": "Delta Lake",
    "explanation": "Delta Lake stores data in Parquet format by default."
  },
  {
    "question": "No SQL, o que significa a cláusula 'GROUP BY'?",
    "options": [
      "Ordenar os resultados",
      "Filtrar registros",
      "Agrupar registros com valores idênticos em colunas especificadas",
      "Limitar o número de resultados"
    ],
    "answer": 2,
    "category": "SQL",
    "explanation": "A cláusula 'GROUP BY' agrupa linhas que compartilham valores em colunas especificadas, permitindo agregações."
  },
  {
    "question": "O que significa ETL em Data Engineering?",
    "options": [
      "Extract, Transform, Load",
      "Evaluate, Test, Launch",
      "Edit, Transfer, Link",
      "Encrypt, Transfer, Log"
    ],
    "answer": 0,
    "category": "Data Engineering",
    "explanation": "ETL significa 'Extract, Transform, Load', que são as etapas para mover e transformar dados entre sistemas."
  },
  {
    "question": "Qual método do DataFrame é usado para juntar dois DataFrames horizontalmente?",
    "options": [
      "join()",
      "union()",
      "merge()",
      "concatenate()"
    ],
    "answer": 0,
    "category": "Dataframes",
    "explanation": "O método 'join()' é usado para combinar dois DataFrames com base em colunas-chave."
  },
  {
    "question": "No Databricks, qual é a função do 'Job Scheduler'?",
    "options": [
      "Agendar e gerenciar a execução de jobs",
      "Visualizar dados em tempo real",
      "Gerenciar permissões de usuário",
      "Criar clusters de computação"
    ],
    "answer": 0,
    "category": "Conceitos do Lakehouse",
    "explanation": "O 'Job Scheduler' permite agendar e monitorar a execução de jobs, como notebooks ou scripts."
  },
  {
    "question": "Qual executor do Airflow é adequado para ambientes de produção com alta carga?",
    "options": [
      "SequentialExecutor",
      "LocalExecutor",
      "CeleryExecutor",
      "DebugExecutor"
    ],
    "answer": 2,
    "category": "Executores",
    "explanation": "O CeleryExecutor é adequado para ambientes de produção distribuídos."
  },
  {
    "question": "Qual método do DataFrame é usado para combinar dois DataFrames verticalmente?",
    "options": [
      "join()",
      "union()",
      "concat()",
      "append()"
    ],
    "answer": 1,
    "category": "Dataframes",
    "explanation": "O método 'union()' é usado para combinar dois DataFrames com o mesmo esquema verticalmente."
  },
  {
    "question": "Qual comando SQL é usado para combinar registros de duas tabelas com base em uma condição comum?",
    "options": [
      "JOIN",
      "UNION",
      "GROUP BY",
      "ORDER BY"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "O comando 'JOIN' é usado para combinar linhas de duas ou mais tabelas com base em uma coluna relacionada entre elas."
  },
  {
    "question": "Como você pausa uma DAG no Airflow?",
    "options": [
      "Removendo o arquivo da DAG",
      "Usando a interface web",
      "Editando o arquivo airflow.cfg",
      "Não é possível pausar uma DAG"
    ],
    "answer": 1,
    "category": "Gerenciamento",
    "explanation": "A pausa de uma DAG pode ser feita através da interface web ou via CLI."
  },
  {
    "question": "Qual comando Delta Lake é usado para otimizar a estrutura de arquivos para melhorar o desempenho de consulta?",
    "options": [
      "VACUUM",
      "OPTIMIZE",
      "REFRESH",
      "COMPACT"
    ],
    "answer": 1,
    "category": "Delta Lake",
    "explanation": "O comando 'OPTIMIZE' realiza compactação de arquivos para melhorar o desempenho das consultas."
  },
  {
    "question": "Para que serve o 'airflow.cfg'?",
    "options": [
      "Configurar parâmetros globais do Airflow",
      "Definir DAGs",
      "Armazenar logs de execução",
      "Gerenciar variáveis de ambiente"
    ],
    "answer": 0,
    "category": "Configuração",
    "explanation": "O 'airflow.cfg' é o arquivo principal de configuração do Airflow."
  },
  {
    "question": "Which programming language is not officially supported in Databricks notebooks?",
    "options": [
      "Python",
      "R",
      "Java",
      "Scala"
    ],
    "answer": 2,
    "category": "Databricks Notebooks",
    "explanation": "Databricks notebooks officially support Python, R, Scala, and SQL, but not Java."
  },
  {
    "question": "No Databricks, o que é um 'Notebook Widget'?",
    "options": [
      "Uma ferramenta para agendar tarefas",
      "Um recurso para adicionar interatividade aos notebooks",
      "Um tipo de cluster de computação",
      "Uma biblioteca para visualização de dados"
    ],
    "answer": 1,
    "category": "Databricks Notebooks",
    "explanation": "Os 'Notebook Widgets' permitem adicionar elementos interativos, como caixas de seleção e menus suspensos, aos notebooks."
  },
  {
    "question": "O que é 'Data Cleansing'?",
    "options": [
      "Processo de coletar dados de diferentes fontes",
      "Análise de dados para extrair insights",
      "Processo de detectar e corrigir ou remover dados incorretos ou inconsistentes",
      "Armazenamento de dados em um data warehouse"
    ],
    "answer": 2,
    "category": "Data Engineering",
    "explanation": "'Data Cleansing' é o processo de melhorar a qualidade dos dados, corrigindo ou removendo informações imprecisas."
  },
  {
    "question": "What does ACID stand for in Delta Lake?",
    "options": [
      "Atomicity, Consistency, Isolation, Durability",
      "Automation, Consistency, Isolation, Durability",
      "Atomicity, Control, Integrity, Durability",
      "Automation, Control, Integrity, Durability"
    ],
    "answer": 0,
    "category": "Delta Lake",
    "explanation": "ACID in Delta Lake stands for Atomicity, Consistency, Isolation, and Durability, which are key properties for reliable transactions."
  },
  {
    "question": "What is a Delta Lake transaction log used for?",
    "options": [
      "Storing metadata and tracking changes",
      "Optimizing query performance",
      "Storing machine learning models",
      "Running SQL queries"
    ],
    "answer": 0,
    "category": "Delta Lake",
    "explanation": "The transaction log records every change made to a Delta Lake table, enabling features like time travel and ACID transactions."
  },
  {
    "question": "Which of the following statements is true about Delta Lake's 'time travel' feature?",
    "options": [
      "It allows you to view previous versions of data",
      "It speeds up job execution",
      "It optimizes queries",
      "It is only available in Databricks SQL"
    ],
    "answer": 0,
    "category": "Delta Lake",
    "explanation": "Time travel in Delta Lake allows users to view and query previous versions of the data."
  },
  {
    "question": "Qual função SQL é usada para concatenar duas ou mais strings?",
    "options": [
      "CONCAT()",
      "MERGE()",
      "COMBINE()",
      "ATTACH()"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "A função 'CONCAT()' é usada para unir duas ou mais strings em uma única string."
  },
  {
    "question": "O que é 'Databricks File System' (DBFS)?",
    "options": [
      "Um sistema de arquivos distribuído",
      "Uma interface de linha de comando",
      "Uma biblioteca de Machine Learning",
      "Um banco de dados relacional"
    ],
    "answer": 0,
    "category": "Conceitos do Lakehouse",
    "explanation": "O DBFS é um sistema de arquivos distribuído que permite o acesso a dados armazenados em nuvem como se fossem locais."
  },
  {
    "question": "Which command is used to create a Delta table in Databricks?",
    "options": [
      "CREATE DELTA TABLE",
      "CREATE TABLE USING DELTA",
      "CREATE EXTERNAL TABLE",
      "CREATE TABLE"
    ],
    "answer": 1,
    "category": "Delta Lake",
    "explanation": "The 'CREATE TABLE USING DELTA' command is used to create a Delta Lake table in Databricks."
  }
]