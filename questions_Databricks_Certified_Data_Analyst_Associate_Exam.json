[
  {
    "question": "No Spark, o que é um 'DataSet'?",
    "options": [
      "Uma coleção distribuída de dados organizada em colunas nomeadas com tipagem forte",
      "Um tipo de banco de dados relacional",
      "Um arquivo de configuração do Spark",
      "Uma biblioteca de visualização de dados"
    ],
    "answer": 0,
    "category": "Apache Spark",
    "explanation": "Um 'DataSet' é uma coleção distribuída de dados com tipagem forte, combinando as vantagens de RDDs e DataFrames."
  },
  {
    "question": "Qual comando SQL é usado para combinar registros de duas tabelas com base em uma coluna comum?",
    "options": [
      "UNION",
      "JOIN",
      "GROUP BY",
      "INTERSECT"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "O comando 'JOIN' é utilizado para combinar registros de duas tabelas com base em uma coluna comum."
  },
  {
    "question": "What is a benefit of using Delta Live Tables in Databricks?",
    "options": [
      "Simplifies real-time analytics pipelines",
      "Provides machine learning libraries",
      "Enhances job scheduling",
      "Supports external database integration"
    ],
    "answer": 0,
    "category": "Real-Time Processing",
    "explanation": "Delta Live Tables simplifies the development of real-time data pipelines by automating operations such as data ingestion and processing."
  },
  {
    "question": "What is the default file format used by Delta Lake?",
    "options": [
      "Parquet",
      "CSV",
      "JSON",
      "ORC"
    ],
    "answer": 0,
    "category": "Delta Lake",
    "explanation": "Delta Lake stores data in Parquet format by default."
  },
  {
    "question": "O que é 'Data Governance' no contexto de gerenciamento de dados?",
    "options": [
      "Análise de dados para insights",
      "Processo de armazenar dados em um data lake",
      "Conjunto de práticas para garantir a qualidade, segurança e gerenciamento de dados",
      "Execução de consultas em bancos de dados"
    ],
    "answer": 2,
    "category": "Data Governance",
    "explanation": "'Data Governance' refere-se às políticas e procedimentos para gerenciar a disponibilidade, usabilidade, integridade e segurança dos dados."
  },
  {
    "question": "What is the role of 'SparkContext' in Spark?",
    "options": [
      "It manages connections and configuration to the Spark cluster",
      "It creates data visualizations",
      "It executes SQL queries",
      "It stores data in tables"
    ],
    "answer": 0,
    "category": "Apache Spark",
    "explanation": "'SparkContext' is the entry point for connecting to a Spark cluster and managing configurations."
  },
  {
    "question": "Qual é a finalidade do comando 'CREATE DATABASE' no SQL?",
    "options": [
      "Atualizar registros em uma tabela",
      "Criar um novo banco de dados",
      "Excluir um banco de dados existente",
      "Adicionar uma nova coluna a uma tabela"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "O comando 'CREATE DATABASE' é usado para criar um novo banco de dados no sistema."
  },
  {
    "question": "Qual é a finalidade do comando 'CREATE VIEW' no SQL?",
    "options": [
      "Criar uma nova tabela",
      "Atualizar uma tabela existente",
      "Criar uma visão virtual de uma consulta",
      "Excluir uma visão existente"
    ],
    "answer": 2,
    "category": "SQL",
    "explanation": "O 'CREATE VIEW' cria uma visão virtual baseada em uma consulta SQL, que pode ser usada como uma tabela."
  },
  {
    "question": "O que é 'Delta Engine' no contexto do Databricks?",
    "options": [
      "Um mecanismo de armazenamento de dados",
      "Uma biblioteca de Machine Learning",
      "Um mecanismo de processamento otimizado para Delta Lake",
      "Uma ferramenta de visualização de dados"
    ],
    "answer": 2,
    "category": "Delta Lake",
    "explanation": "O 'Delta Engine' é um mecanismo de processamento de consultas de alto desempenho otimizado para trabalhar com o Delta Lake."
  },
  {
    "question": "Which Delta Lake feature ensures that only data matching the table's schema can be written?",
    "options": [
      "Data Versioning",
      "Schema Enforcement",
      "Schema Evolution",
      "Time Travel"
    ],
    "answer": 1,
    "category": "Delta Lake",
    "explanation": "'Schema Enforcement' ensures that only data conforming to the table's schema is allowed."
  },
  {
    "question": "What does ACID stand for in Delta Lake?",
    "options": [
      "Atomicity, Consistency, Isolation, Durability",
      "Automation, Consistency, Isolation, Durability",
      "Atomicity, Control, Integrity, Durability",
      "Automation, Control, Integrity, Durability"
    ],
    "answer": 0,
    "category": "Delta Lake",
    "explanation": "ACID in Delta Lake stands for Atomicity, Consistency, Isolation, and Durability, which are key properties for reliable transactions."
  },
  {
    "question": "Which function is used in SQL to calculate the total sum of a numeric column?",
    "options": [
      "COUNT()",
      "SUM()",
      "AVG()",
      "MIN()"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "The 'SUM()' function is used to calculate the total sum of values in a numeric column."
  },
  {
    "question": "Which of the following Databricks features enables real-time stream processing?",
    "options": [
      "Delta Lake",
      "Spark SQL",
      "Structured Streaming",
      "Databricks Jobs"
    ],
    "answer": 2,
    "category": "Real-Time Processing",
    "explanation": "Structured Streaming allows real-time processing of data streams in Databricks."
  },
  {
    "question": "Which feature in Delta Lake allows users to query previous versions of data?",
    "options": [
      "Z-Ordering",
      "Time Travel",
      "Data Skew",
      "Cluster Mode"
    ],
    "answer": 1,
    "category": "Delta Lake",
    "explanation": "Delta Lake's 'Time Travel' feature allows users to access previous versions of data for auditing or rollback."
  },
  {
    "question": "Which Databricks feature allows you to track the version history of Delta Lake tables?",
    "options": [
      "Schema Evolution",
      "Time Travel",
      "Delta Metrics",
      "Photon"
    ],
    "answer": 1,
    "category": "Delta Lake",
    "explanation": "Time Travel allows you to view and query previous versions of Delta Lake tables."
  },
  {
    "question": "Qual comando SQL é usado para combinar registros de duas tabelas baseadas em uma coluna relacionada?",
    "options": [
      "UNION",
      "JOIN",
      "INTERSECT",
      "MERGE"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "O 'JOIN' combina registros de duas tabelas com base em uma coluna compartilhada ou relacionada."
  },
  {
    "question": "Qual é o papel do 'Driver' no Spark?",
    "options": [
      "Executar tarefas individuais",
      "Coordenar a execução de jobs e tarefas",
      "Armazenar dados em cache",
      "Visualizar resultados"
    ],
    "answer": 1,
    "category": "Apache Spark",
    "explanation": "O 'Driver' é o processo que coordena a execução do aplicativo Spark, gerenciando jobs e tarefas."
  },
  {
    "question": "Which of the following statements is true about Delta Lake's 'time travel' feature?",
    "options": [
      "It allows you to view previous versions of data",
      "It speeds up job execution",
      "It optimizes queries",
      "It is only available in Databricks SQL"
    ],
    "answer": 0,
    "category": "Delta Lake",
    "explanation": "Time travel in Delta Lake allows users to view and query previous versions of the data."
  },
  {
    "question": "No Spark, qual é a função da operação 'filter()'?",
    "options": [
      "Aplicar uma função em cada elemento",
      "Selecionar elementos que atendem a uma condição",
      "Reduzir o número de partições",
      "Agrupar elementos com base em uma chave"
    ],
    "answer": 1,
    "category": "Apache Spark",
    "explanation": "A função 'filter()' no Spark é usada para retornar apenas os elementos que atendem a uma condição específica."
  },
  {
    "question": "Qual é o propósito do 'SparkContext' no Spark?",
    "options": [
      "Gerenciar a configuração e conexão com o cluster Spark",
      "Criar visualizações de dados",
      "Executar consultas SQL",
      "Armazenar dados em tabelas"
    ],
    "answer": 0,
    "category": "Apache Spark",
    "explanation": "O 'SparkContext' é o ponto de entrada para a funcionalidade do Spark, permitindo a conexão com o cluster e a configuração de parâmetros."
  },
  {
    "question": "What does the 'COUNT()' function in SQL return?",
    "options": [
      "The total number of rows",
      "The sum of a column",
      "The average of values",
      "The maximum value in a column"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "The 'COUNT()' function returns the total number of rows that match a specified condition."
  },
  {
    "question": "Which programming language is not officially supported in Databricks notebooks?",
    "options": [
      "Python",
      "R",
      "Java",
      "Scala"
    ],
    "answer": 2,
    "category": "Databricks Notebooks",
    "explanation": "Databricks notebooks officially support Python, R, Scala, and SQL, but not Java."
  },
  {
    "question": "Qual função SQL é usada para calcular a média de um conjunto de valores?",
    "options": [
      "SUM()",
      "COUNT()",
      "AVG()",
      "MAX()"
    ],
    "answer": 2,
    "category": "SQL",
    "explanation": "A função 'AVG()' retorna a média aritmética dos valores em uma coluna."
  },
  {
    "question": "Qual é o principal benefício de usar o Delta Lake no Databricks?",
    "options": [
      "Facilidade na criação de visualizações",
      "Suporte a transações ACID",
      "Execução de Machine Learning",
      "Integração com sistemas de terceiros"
    ],
    "answer": 1,
    "category": "Delta Lake",
    "explanation": "O Delta Lake oferece suporte a transações ACID, garantindo consistência e confiabilidade nos dados."
  },
  {
    "question": "Qual é a diferença entre 'INNER JOIN' e 'LEFT JOIN' no SQL?",
    "options": [
      "'INNER JOIN' retorna todas as linhas, 'LEFT JOIN' retorna apenas correspondências",
      "'INNER JOIN' retorna correspondências exatas, 'LEFT JOIN' inclui todas as linhas da tabela da esquerda",
      "'LEFT JOIN' retorna correspondências exatas, 'INNER JOIN' inclui todas as linhas da tabela da esquerda",
      "'LEFT JOIN' não existe no SQL"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "'INNER JOIN' retorna apenas as linhas com correspondências em ambas as tabelas, enquanto 'LEFT JOIN' retorna todas as linhas da tabela da esquerda, incluindo as não correspondidas."
  },
  {
    "question": "Qual é a finalidade da função 'COALESCE()' no SQL?",
    "options": [
      "Combinar várias colunas em uma",
      "Substituir valores nulos por um valor especificado",
      "Dividir uma coluna em várias",
      "Contar o número de valores não nulos"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "A função 'COALESCE()' retorna o primeiro valor não nulo em uma lista de argumentos."
  },
  {
    "question": "Qual é o propósito do comando 'CREATE INDEX' no SQL?",
    "options": [
      "Criar uma nova tabela",
      "Adicionar uma coluna a uma tabela",
      "Melhorar a velocidade das consultas em uma tabela",
      "Excluir registros duplicados"
    ],
    "answer": 2,
    "category": "SQL",
    "explanation": "O comando 'CREATE INDEX' é usado para criar um índice que acelera a recuperação de dados em uma tabela."
  },
  {
    "question": "What is the main purpose of 'Time Travel' in Delta Lake?",
    "options": [
      "To optimize query performance",
      "To store machine learning models",
      "To query previous versions of data",
      "To delete old data"
    ],
    "answer": 2,
    "category": "Delta Lake",
    "explanation": "'Time Travel' allows users to query earlier versions of data for auditing or recovery purposes."
  },
  {
    "question": "O que é 'Shuffling' no Spark?",
    "options": [
      "Processo de reorganização de dados entre partições",
      "Remoção de dados duplicados",
      "Combinação de dois datasets",
      "Armazenamento de dados em cache"
    ],
    "answer": 0,
    "category": "Apache Spark",
    "explanation": "'Shuffling' é o processo de redistribuir dados entre partições, o que pode ser custoso em termos de desempenho."
  },
  {
    "question": "O que é o 'Auto Loader' no contexto do Databricks?",
    "options": [
      "Uma ferramenta para carregar dados manualmente",
      "Um serviço para automatizar a ingestão de dados",
      "Um recurso para limpar dados duplicados",
      "Um módulo de Machine Learning"
    ],
    "answer": 1,
    "category": "Ingestão de Dados",
    "explanation": "O Auto Loader é um recurso que automatiza a ingestão contínua de dados em tabelas Delta."
  },
  {
    "question": "Which command is used to remove a table from a SQL database?",
    "options": [
      "DELETE",
      "DROP",
      "TRUNCATE",
      "REMOVE"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "The 'DROP' command is used to remove a table from a SQL database, including its structure and data."
  },
  {
    "question": "Which SQL command is used to add a new column to an existing table?",
    "options": [
      "ALTER TABLE ... ADD COLUMN",
      "UPDATE TABLE ... ADD COLUMN",
      "CREATE COLUMN",
      "ADD COLUMN TO TABLE"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "The 'ALTER TABLE ... ADD COLUMN' command adds a new column to an existing table in SQL."
  },
  {
    "question": "Qual função SQL retorna o maior valor de uma coluna numérica?",
    "options": [
      "SUM()",
      "COUNT()",
      "MIN()",
      "MAX()"
    ],
    "answer": 3,
    "category": "SQL",
    "explanation": "A função 'MAX()' retorna o maior valor encontrado em uma coluna específica."
  },
  {
    "question": "In Delta Lake, what does ACID stand for?",
    "options": [
      "Atomicity, Consistency, Isolation, Durability",
      "Automation, Consistency, Isolation, Durability",
      "Atomicity, Control, Integrity, Durability",
      "Automation, Control, Isolation, Durability"
    ],
    "answer": 0,
    "category": "Delta Lake",
    "explanation": "ACID stands for Atomicity, Consistency, Isolation, and Durability, which are critical properties of reliable transactions."
  },
  {
    "question": "Qual função SQL é usada para concatenar duas ou mais strings?",
    "options": [
      "CONCAT()",
      "MERGE()",
      "COMBINE()",
      "ATTACH()"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "A função 'CONCAT()' é usada para unir duas ou mais strings em uma única string."
  },
  {
    "question": "Which command in SQL is used to rename a table?",
    "options": [
      "ALTER TABLE ... RENAME TO",
      "RENAME TABLE",
      "UPDATE TABLE",
      "CHANGE TABLE NAME"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "The 'ALTER TABLE ... RENAME TO' command is used to rename a table in SQL."
  },
  {
    "question": "Which of the following is a high-level API in Spark?",
    "options": [
      "Cluster Manager",
      "RDD",
      "DataFrame",
      "Task Scheduler"
    ],
    "answer": 2,
    "category": "Apache Spark",
    "explanation": "The DataFrame API in Spark provides a high-level abstraction for working with structured data."
  },
  {
    "question": "Qual é a finalidade do comando 'DELETE FROM' no SQL?",
    "options": [
      "Remover uma tabela",
      "Excluir registros específicos de uma tabela",
      "Limpar todos os dados de uma tabela",
      "Excluir um banco de dados inteiro"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "O 'DELETE FROM' remove registros específicos de uma tabela com base em uma condição."
  },
  {
    "question": "Which SQL command is used to change data in an existing table?",
    "options": [
      "ALTER TABLE",
      "UPDATE",
      "INSERT INTO",
      "DROP"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "The 'UPDATE' command is used to modify existing records in a table."
  },
  {
    "question": "In SQL, which command is used to rename an existing table?",
    "options": [
      "ALTER TABLE ... RENAME TO",
      "RENAME TABLE",
      "UPDATE TABLE",
      "CHANGE TABLE NAME"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "The 'ALTER TABLE ... RENAME TO' command is used to rename an existing table in SQL."
  },
  {
    "question": "Qual é a finalidade da função 'NVL()' no SQL?",
    "options": [
      "Substituir valores nulos por um valor especificado",
      "Remover espaços em branco de uma string",
      "Converter números em strings",
      "Concatenar múltiplas strings"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "A função 'NVL()' retorna o segundo parâmetro se o primeiro for nulo; caso contrário, retorna o primeiro parâmetro."
  },
  {
    "question": "No contexto do Spark, o que é uma 'Action'?",
    "options": [
      "Uma operação que retorna um valor ao driver",
      "Uma transformação de dados",
      "Um método para definir esquemas",
      "Uma ferramenta de visualização"
    ],
    "answer": 0,
    "category": "Apache Spark",
    "explanation": "Uma 'Action' é uma operação que força a computação e retorna um resultado ao programa do driver."
  },
  {
    "question": "No Databricks, o que é 'Delta Live Tables'?",
    "options": [
      "Uma ferramenta para criar pipelines de dados em tempo real",
      "Uma biblioteca de visualização de dados",
      "Um sistema de otimização de queries",
      "Um editor de código SQL"
    ],
    "answer": 0,
    "category": "Delta Lake",
    "explanation": "'Delta Live Tables' é usada para criar e gerenciar pipelines de dados em tempo real no Databricks."
  },
  {
    "question": "Which tool in Databricks is used to track and manage machine learning models?",
    "options": [
      "Delta Lake",
      "SQL Analytics",
      "MLflow",
      "Structured Streaming"
    ],
    "answer": 2,
    "category": "Machine Learning",
    "explanation": "MLflow is a platform integrated with Databricks to track, manage, and deploy machine learning models."
  },
  {
    "question": "Qual comando SQL é usado para remover uma tabela do banco de dados?",
    "options": [
      "DELETE TABLE",
      "DROP TABLE",
      "REMOVE TABLE",
      "CLEAR TABLE"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "O comando 'DROP TABLE' é utilizado para remover completamente uma tabela e seus dados do banco de dados."
  },
  {
    "question": "O que é um 'External Table' no contexto do SQL?",
    "options": [
      "Uma tabela armazenada fora do banco de dados",
      "Uma visão temporária de dados",
      "Uma tabela que referencia dados externos sem importá-los",
      "Uma tabela que existe apenas durante a sessão atual"
    ],
    "answer": 2,
    "category": "Databricks SQL",
    "explanation": "Uma 'External Table' referencia dados armazenados fora do banco de dados, permitindo consultas sem importação."
  },
  {
    "question": "In Delta Lake, what does 'Schema Enforcement' ensure?",
    "options": [
      "Data encryption is applied",
      "Data meets the schema requirements before being written",
      "Queries are optimized automatically",
      "Data is partitioned across multiple nodes"
    ],
    "answer": 1,
    "category": "Delta Lake",
    "explanation": "'Schema Enforcement' ensures that only data conforming to the defined schema is written to a Delta Lake table."
  },
  {
    "question": "O que é 'Data Skew' em processamento distribuído?",
    "options": [
      "Quando os dados estão uniformemente distribuídos",
      "Quando a maioria dos dados está concentrada em poucas chaves, causando desequilíbrio",
      "Quando os dados são corrompidos durante a transferência",
      "Quando os dados estão encriptados"
    ],
    "answer": 1,
    "category": "Data Engineering",
    "explanation": "'Data Skew' ocorre quando alguns nós processam muito mais dados que outros, levando a um desempenho desigual."
  },
  {
    "question": "No SQL, para que serve a cláusula 'UNION'?",
    "options": [
      "Combinar os resultados de duas ou mais consultas sem duplicatas",
      "Encontrar interseção entre duas consultas",
      "Atualizar múltiplas tabelas ao mesmo tempo",
      "Excluir registros duplicados em uma tabela"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "A cláusula 'UNION' combina os resultados de duas ou mais consultas, removendo duplicatas."
  },
  {
    "question": "Qual comando SQL é usado para modificar os dados existentes em uma tabela?",
    "options": [
      "ALTER TABLE",
      "UPDATE",
      "MODIFY",
      "CHANGE"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "O comando 'UPDATE' é utilizado para modificar os dados existentes em uma tabela específica."
  },
  {
    "question": "O que é 'DataFrame' no Apache Spark?",
    "options": [
      "Uma coleção distribuída de dados organizada em colunas nomeadas",
      "Um tipo de banco de dados relacional",
      "Um arquivo de configuração do Spark",
      "Uma biblioteca de visualização de dados"
    ],
    "answer": 0,
    "category": "Conceitos do Lakehouse",
    "explanation": "Um DataFrame é uma estrutura de dados do Spark que armazena dados tabulares em colunas nomeadas, similar a uma tabela SQL."
  },
  {
    "question": "Qual comando SQL é usado para adicionar uma nova coluna a uma tabela existente?",
    "options": [
      "ALTER TABLE ... ADD COLUMN",
      "UPDATE TABLE ... ADD COLUMN",
      "INSERT INTO ... COLUMN",
      "CREATE COLUMN IN TABLE"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "O comando 'ALTER TABLE ... ADD COLUMN' é usado para adicionar uma nova coluna a uma tabela existente."
  },
  {
    "question": "O que é 'Checkpointing' no Spark Streaming?",
    "options": [
      "Uma técnica para recuperar dados perdidos",
      "Salvar o estado de um streaming em disco para tolerância a falhas",
      "Uma forma de otimizar consultas",
      "Uma técnica de balanceamento de carga"
    ],
    "answer": 1,
    "category": "Streaming",
    "explanation": "'Checkpointing' salva o estado do streaming em disco, permitindo que o sistema se recupere em caso de falhas."
  },
  {
    "question": "No Databricks, o que é 'Auto Termination' de clusters?",
    "options": [
      "Encerramento automático de clusters após um período de inatividade",
      "Escalonamento automático de recursos do cluster",
      "Reinício automático de clusters falhos",
      "Atualização automática do software do cluster"
    ],
    "answer": 0,
    "category": "Cluster Management",
    "explanation": "'Auto Termination' encerra automaticamente um cluster se ele permanecer ocioso por um período definido, economizando recursos."
  },
  {
    "question": "O que é 'Watermarking' no Spark Structured Streaming?",
    "options": [
      "Adicionar marcas d'água em dados para segurança",
      "Limitar o estado necessário para agregações tardias",
      "Marcar dados duplicados",
      "Priorizar certos dados durante o processamento"
    ],
    "answer": 1,
    "category": "Streaming",
    "explanation": "'Watermarking' é usado para descartar dados atrasados e limitar a quantidade de estado mantido para operações de agregação."
  },
  {
    "question": "O que é um 'Executor' no contexto do Spark?",
    "options": [
      "O processo que coordena o cluster",
      "Um processo responsável por executar tarefas e armazenar dados",
      "Uma interface de usuário para monitorar jobs",
      "Um módulo para escrever código SQL"
    ],
    "answer": 1,
    "category": "Apache Spark",
    "explanation": "Um 'Executor' é um processo que executa tarefas individuais e armazena dados em cache conforme necessário."
  },
  {
    "question": "What is a Delta Lake transaction log used for?",
    "options": [
      "Storing metadata and tracking changes",
      "Optimizing query performance",
      "Storing machine learning models",
      "Running SQL queries"
    ],
    "answer": 0,
    "category": "Delta Lake",
    "explanation": "The transaction log records every change made to a Delta Lake table, enabling features like time travel and ACID transactions."
  },
  {
    "question": "Qual função SQL é usada para arredondar um número para um número específico de decimais?",
    "options": [
      "ROUND()",
      "FLOOR()",
      "CEIL()",
      "TRUNC()"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "A função 'ROUND()' é usada para arredondar um número para um número especificado de casas decimais."
  },
  {
    "question": "No contexto de visualização de dados, para que é usado um gráfico de linhas?",
    "options": [
      "Comparar categorias distintas",
      "Mostrar a distribuição de uma variável",
      "Representar tendências ao longo do tempo",
      "Analisar a relação entre duas variáveis numéricas"
    ],
    "answer": 2,
    "category": "Visualização de Dados",
    "explanation": "Gráficos de linhas são ideais para mostrar como os valores de uma variável mudam ao longo do tempo."
  },
  {
    "question": "O que significa 'APIs de Alto Nível' no Spark?",
    "options": [
      "APIs que interagem diretamente com o código binário",
      "APIs que fornecem abstrações como DataFrames e Datasets",
      "APIs para gerenciar clusters",
      "APIs para visualização de dados"
    ],
    "answer": 1,
    "category": "Apache Spark",
    "explanation": "As 'APIs de Alto Nível' do Spark incluem DataFrames e Datasets, que facilitam a manipulação de dados estruturados."
  },
  {
    "question": "No Databricks, o que é um 'Job Cluster'?",
    "options": [
      "Um cluster dedicado para execução de jobs agendados",
      "Um cluster para uso interativo",
      "Um grupo de clusters interconectados",
      "Um cluster utilizado para armazenamento de dados"
    ],
    "answer": 0,
    "category": "Cluster Management",
    "explanation": "Um 'Job Cluster' é criado automaticamente para executar um job específico e é encerrado após a conclusão."
  },
  {
    "question": "What does the 'ALTER TABLE ... ADD COLUMN' command do in SQL?",
    "options": [
      "Adds a new column to an existing table",
      "Modifies data in a column",
      "Renames a column",
      "Deletes a column from a table"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "The 'ALTER TABLE ... ADD COLUMN' command is used to add a new column to an existing table."
  },
  {
    "question": "What is the primary function of Databricks SQL?",
    "options": [
      "To create machine learning models",
      "To analyze data using SQL queries and create visualizations",
      "To manage distributed clusters",
      "To automate job scheduling"
    ],
    "answer": 1,
    "category": "Databricks SQL",
    "explanation": "Databricks SQL is primarily used for querying data using SQL and creating visualizations."
  },
  {
    "question": "Which of the following is a feature of Databricks notebooks?",
    "options": [
      "Support for multiple languages",
      "Version control integration",
      "Real-time collaboration",
      "All of the above"
    ],
    "answer": 3,
    "category": "Databricks Notebooks",
    "explanation": "Databricks notebooks support multiple languages, real-time collaboration, and integration with version control systems."
  },
  {
    "question": "What does the 'SUM()' function do in SQL?",
    "options": [
      "It counts the number of rows in a table",
      "It adds together the values in a column",
      "It calculates the average value of a column",
      "It returns the highest value in a column"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "The 'SUM()' function calculates the sum of values in a numeric column."
  },
  {
    "question": "Qual é o papel do 'Command Mode' em um notebook do Databricks?",
    "options": [
      "Executar comandos do sistema operacional",
      "Navegar e editar células do notebook",
      "Compilar código de programação",
      "Visualizar logs de execução"
    ],
    "answer": 1,
    "category": "Databricks Notebooks",
    "explanation": "O 'Command Mode' permite que o usuário navegue entre células e execute operações de edição no notebook."
  },
  {
    "question": "No Databricks, o que é um 'Notebook Widget'?",
    "options": [
      "Uma ferramenta para agendar tarefas",
      "Um recurso para adicionar interatividade aos notebooks",
      "Um tipo de cluster de computação",
      "Uma biblioteca para visualização de dados"
    ],
    "answer": 1,
    "category": "Databricks Notebooks",
    "explanation": "Os 'Notebook Widgets' permitem adicionar elementos interativos, como caixas de seleção e menus suspensos, aos notebooks."
  },
  {
    "question": "What is the purpose of the 'GRANT' command in SQL?",
    "options": [
      "To update data in a table",
      "To remove a database",
      "To give permissions to a user",
      "To create a new database"
    ],
    "answer": 2,
    "category": "Data Governance",
    "explanation": "The 'GRANT' command is used to provide specific permissions to users on database objects."
  },
  {
    "question": "O que é um 'Managed Table' no Databricks?",
    "options": [
      "Uma tabela cujos dados são gerenciados pelo sistema",
      "Uma tabela externa",
      "Uma tabela temporária",
      "Uma tabela que existe apenas em memória"
    ],
    "answer": 0,
    "category": "Databricks SQL",
    "explanation": "Em uma 'Managed Table', o Databricks gerencia tanto os metadados quanto os dados da tabela."
  },
  {
    "question": "What does the 'MERGE INTO' command do in Delta Lake?",
    "options": [
      "Updates and inserts data into a table based on conditions",
      "Combines multiple tables into one",
      "Deletes data from multiple tables",
      "Removes duplicates from a table"
    ],
    "answer": 0,
    "category": "Delta Lake",
    "explanation": "The 'MERGE INTO' command allows users to update and insert data into a Delta Lake table based on specified conditions."
  },
  {
    "question": "Which of the following is a key feature of Delta Lake?",
    "options": [
      "Versioning",
      "Batch processing only",
      "Machine learning support",
      "No schema enforcement"
    ],
    "answer": 0,
    "category": "Delta Lake",
    "explanation": "Delta Lake's versioning feature allows you to track and manage multiple versions of data over time."
  },
  {
    "question": "What is the primary purpose of Databricks SQL?",
    "options": [
      "To provide a collaborative environment for data science",
      "To manage and organize data lakes",
      "To analyze data using SQL queries and create visualizations",
      "To train machine learning models"
    ],
    "answer": 2,
    "category": "Databricks SQL",
    "explanation": "Databricks SQL is primarily used for querying data with SQL and creating visualizations."
  },
  {
    "question": "In Databricks, what is a 'Notebook Widget' used for?",
    "options": [
      "To add interactivity to notebooks",
      "To track machine learning experiments",
      "To manage cluster resources",
      "To visualize data"
    ],
    "answer": 0,
    "category": "Databricks Notebooks",
    "explanation": "Notebook Widgets add interactivity, such as dropdowns or text boxes, to notebooks for dynamic inputs."
  },
  {
    "question": "O que significa 'time travel' no contexto do Delta Lake?",
    "options": [
      "Permite restaurar dados de backups",
      "Permite consultar versões anteriores dos dados",
      "Aumenta a velocidade das consultas",
      "Fornece segurança para dados antigos"
    ],
    "answer": 1,
    "category": "Delta Lake",
    "explanation": "'Time travel' permite acessar versões anteriores de dados no Delta Lake para auditoria ou recuperação."
  },
  {
    "question": "Qual é a finalidade da cláusula 'HAVING' no SQL?",
    "options": [
      "Filtrar resultados após uma agregação",
      "Ordenar os resultados",
      "Limitar o número de resultados",
      "Agrupar registros com valores idênticos"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "A cláusula 'HAVING' é usada para filtrar resultados após uma operação de agregação com 'GROUP BY'."
  },
  {
    "question": "What is the function of the 'MERGE INTO' command in Delta Lake?",
    "options": [
      "To combine two datasets into one",
      "To delete data from a table",
      "To update and insert data based on conditions",
      "To alter the schema of a table"
    ],
    "answer": 2,
    "category": "Delta Lake",
    "explanation": "MERGE INTO is used to update and insert data into a Delta Lake table based on specified conditions."
  },
  {
    "question": "No Databricks, o que é 'Unity Catalog'?",
    "options": [
      "Um catálogo unificado de dados para governança",
      "Um serviço de armazenamento em nuvem",
      "Uma ferramenta de visualização",
      "Um editor de código"
    ],
    "answer": 0,
    "category": "Data Governance",
    "explanation": "O 'Unity Catalog' é um serviço de governança que oferece gerenciamento centralizado de metadados e permissões."
  },
  {
    "question": "O que significa 'idempotência' no contexto de operações de dados?",
    "options": [
      "Uma operação que falha se repetida",
      "Uma operação que produz o mesmo resultado mesmo se executada várias vezes",
      "Uma operação que sempre retorna valores únicos",
      "Uma operação que depende da ordem de execução"
    ],
    "answer": 1,
    "category": "Data Engineering",
    "explanation": "Uma operação idempotente produz o mesmo resultado independentemente de quantas vezes é executada."
  },
  {
    "question": "Qual é a finalidade da função 'DATEDIFF()' no SQL?",
    "options": [
      "Calcular a diferença entre duas datas",
      "Formatar uma data em um determinado padrão",
      "Adicionar dias a uma data",
      "Extrair o dia da semana de uma data"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "A função 'DATEDIFF()' é usada para calcular a diferença entre duas datas especificadas."
  },
  {
    "question": "No Databricks, o que é um 'Notebook Job'?",
    "options": [
      "Um job que executa um notebook específico",
      "Um job que gerencia clusters",
      "Um job que realiza backup de dados",
      "Um job que atualiza a interface de usuário"
    ],
    "answer": 0,
    "category": "Databricks Notebooks",
    "explanation": "Um 'Notebook Job' permite agendar a execução de um notebook em um horário específico ou de forma recorrente."
  },
  {
    "question": "Qual é a diferença entre 'DROP' e 'TRUNCATE' no SQL?",
    "options": [
      "'DROP' remove todos os registros, 'TRUNCATE' remove a estrutura da tabela",
      "'DROP' remove a estrutura da tabela, 'TRUNCATE' remove todos os registros",
      "Não há diferença entre eles",
      "'TRUNCATE' é mais lento que 'DROP'"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "'DROP' exclui a tabela inteira, incluindo estrutura e dados; 'TRUNCATE' remove apenas os dados, mantendo a estrutura."
  },
  {
    "question": "Which Databricks tool is used for managing machine learning lifecycle?",
    "options": [
      "SQL Analytics",
      "Delta Lake",
      "MLflow",
      "Structured Streaming"
    ],
    "answer": 2,
    "category": "Machine Learning",
    "explanation": "MLflow is a tool integrated with Databricks to manage the end-to-end machine learning lifecycle."
  },
  {
    "question": "Which feature in Databricks is used to track and manage machine learning experiments?",
    "options": [
      "Photon Engine",
      "MLflow",
      "Structured Streaming",
      "Delta Live Tables"
    ],
    "answer": 1,
    "category": "Machine Learning",
    "explanation": "MLflow is a tool integrated with Databricks for managing machine learning experiments and tracking model performance."
  },
  {
    "question": "What is the role of the 'Spark UI' in Databricks?",
    "options": [
      "To manage cluster configurations",
      "To visualize datasets",
      "To monitor job execution and performance",
      "To track machine learning models"
    ],
    "answer": 2,
    "category": "Monitoring",
    "explanation": "The 'Spark UI' provides detailed information on job execution, including task times and stages, allowing performance monitoring."
  },
  {
    "question": "Which function in SQL is used to group rows that have the same values in specified columns?",
    "options": [
      "GROUP BY",
      "ORDER BY",
      "HAVING",
      "JOIN"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "The GROUP BY clause groups rows that share the same values in specified columns, allowing for aggregate functions."
  },
  {
    "question": "Which command is used to create a Delta table in Databricks?",
    "options": [
      "CREATE DELTA TABLE",
      "CREATE TABLE USING DELTA",
      "CREATE EXTERNAL TABLE",
      "CREATE TABLE"
    ],
    "answer": 1,
    "category": "Delta Lake",
    "explanation": "The 'CREATE TABLE USING DELTA' command is used to create a Delta Lake table in Databricks."
  },
  {
    "question": "Qual é a finalidade do comando 'DROP DATABASE' no SQL?",
    "options": [
      "Remover um banco de dados e todos os seus objetos",
      "Atualizar registros em um banco de dados",
      "Criar um novo banco de dados",
      "Listar todos os bancos de dados"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "O comando 'DROP DATABASE' exclui completamente um banco de dados e todos os seus objetos associados."
  },
  {
    "question": "Qual é a função do comando 'DROP TABLE' no SQL?",
    "options": [
      "Remover todas as linhas de uma tabela",
      "Excluir uma tabela do banco de dados",
      "Limpar dados duplicados de uma tabela",
      "Criar uma nova tabela vazia"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "O comando 'DROP TABLE' é usado para excluir completamente uma tabela do banco de dados, incluindo sua estrutura e dados."
  },
  {
    "question": "Qual é a finalidade da função 'LOWER()' no SQL?",
    "options": [
      "Converter uma string para minúsculas",
      "Encontrar o menor valor em uma coluna",
      "Remover caracteres especiais de uma string",
      "Comparar duas strings"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "A função 'LOWER()' converte todos os caracteres de uma string para letras minúsculas."
  },
  {
    "question": "Qual é a vantagem de usar 'Photon' no Databricks?",
    "options": [
      "Aumenta a segurança dos dados",
      "Melhora o desempenho de consultas SQL",
      "Simplifica a criação de pipelines",
      "Permite gerenciamento de permissões"
    ],
    "answer": 1,
    "category": "Databricks SQL",
    "explanation": "'Photon' é um mecanismo de execução nativo no Databricks que otimiza o desempenho de consultas SQL."
  },
  {
    "question": "O que é 'Data Cleansing'?",
    "options": [
      "Processo de coletar dados de diferentes fontes",
      "Análise de dados para extrair insights",
      "Processo de detectar e corrigir ou remover dados incorretos ou inconsistentes",
      "Armazenamento de dados em um data warehouse"
    ],
    "answer": 2,
    "category": "Data Engineering",
    "explanation": "'Data Cleansing' é o processo de melhorar a qualidade dos dados, corrigindo ou removendo informações imprecisas."
  },
  {
    "question": "No contexto do Databricks, o que é um 'Workspace'?",
    "options": [
      "Um ambiente colaborativo para projetos",
      "Uma máquina virtual individual",
      "Um tipo de cluster de computação",
      "Uma biblioteca de funções pré-construídas"
    ],
    "answer": 0,
    "category": "Conceitos do Lakehouse",
    "explanation": "Um 'Workspace' é um ambiente onde usuários podem colaborar em notebooks, trabalhos e outros recursos."
  },
  {
    "question": "No contexto de segurança de dados, o que é 'Mascaramento de Dados'?",
    "options": [
      "Criptografar dados para proteção",
      "Ocultar dados sensíveis em resultados de consultas",
      "Excluir dados obsoletos",
      "Fazer backup de dados importantes"
    ],
    "answer": 1,
    "category": "Data Governance",
    "explanation": "'Mascaramento de Dados' envolve ocultar informações sensíveis, mostrando valores fictícios ou parciais aos usuários."
  },
  {
    "question": "What is the function of the 'HAVING' clause in SQL?",
    "options": [
      "To filter rows before aggregation",
      "To limit the number of rows returned",
      "To filter rows after aggregation",
      "To group rows by common values"
    ],
    "answer": 2,
    "category": "SQL",
    "explanation": "The 'HAVING' clause is used to filter rows after an aggregation is performed."
  },
  {
    "question": "No SQL, o que faz a cláusula 'HAVING'?",
    "options": [
      "Filtra resultados após agregações",
      "Ordena os resultados",
      "Limita o número de resultados",
      "Agrupa registros com valores idênticos"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "A cláusula 'HAVING' é usada para filtrar grupos de resultados após uma agregação com 'GROUP BY'."
  },
  {
    "question": "Qual é a função da operação 'Collect' no Spark?",
    "options": [
      "Coletar dados para o driver como um array",
      "Distribuir dados entre executores",
      "Persistir dados em disco",
      "Filtrar dados com base em uma condição"
    ],
    "answer": 0,
    "category": "Apache Spark",
    "explanation": "A operação 'Collect' recupera todos os elementos do RDD ou DataFrame e os traz para o driver como um array."
  },
  {
    "question": "In Databricks, what is a 'Workspace'?",
    "options": [
      "A collaborative environment for projects",
      "A virtual machine",
      "A storage system",
      "A cluster management tool"
    ],
    "answer": 0,
    "category": "Databricks Notebooks",
    "explanation": "A 'Workspace' in Databricks is a collaborative environment where users can share notebooks and work on projects together."
  },
  {
    "question": "No SQL, o que significa a cláusula 'GROUP BY'?",
    "options": [
      "Ordenar os resultados",
      "Filtrar registros",
      "Agrupar registros com valores idênticos em colunas especificadas",
      "Limitar o número de resultados"
    ],
    "answer": 2,
    "category": "SQL",
    "explanation": "A cláusula 'GROUP BY' agrupa linhas que compartilham valores em colunas especificadas, permitindo agregações."
  },
  {
    "question": "Which Databricks feature allows real-time collaboration on notebooks?",
    "options": [
      "Photon Engine",
      "Delta Live Tables",
      "Real-Time Collaboration",
      "Job Scheduler"
    ],
    "answer": 2,
    "category": "Databricks Notebooks",
    "explanation": "Databricks allows real-time collaboration on notebooks, enabling multiple users to edit and run code simultaneously."
  },
  {
    "question": "O que é 'Persistência' no contexto do Spark?",
    "options": [
      "Armazenar dados em cache ou memória para reutilização",
      "Salvar dados em disco permanentemente",
      "Remover dados não utilizados",
      "Compactar dados para economizar espaço"
    ],
    "answer": 0,
    "category": "Apache Spark",
    "explanation": "A 'Persistência' permite que os usuários armazenem RDDs em cache ou memória para uso repetido, melhorando o desempenho."
  },
  {
    "question": "Which of the following is a benefit of Delta Lake's time travel feature?",
    "options": [
      "Viewing older versions of data",
      "Faster query execution",
      "Schema enforcement",
      "Support for machine learning"
    ],
    "answer": 0,
    "category": "Delta Lake",
    "explanation": "Time travel allows users to access previous versions of data for auditing or recovery."
  },
  {
    "question": "O que é 'Cluster Auto-Scaling' no Databricks?",
    "options": [
      "A capacidade de ajustar automaticamente o tamanho do cluster com base na carga de trabalho",
      "Um método de segurança de clusters",
      "Uma ferramenta para criar visualizações",
      "Um serviço para armazenar dados"
    ],
    "answer": 0,
    "category": "Conceitos do Lakehouse",
    "explanation": "'Cluster Auto-Scaling' permite que o Databricks aumente ou diminua automaticamente os recursos do cluster conforme necessário."
  },
  {
    "question": "No SQL, o que faz a cláusula 'LIMIT'?",
    "options": [
      "Agrupa resultados",
      "Ordena resultados",
      "Restringe o número de linhas retornadas",
      "Filtra registros com base em uma condição"
    ],
    "answer": 2,
    "category": "SQL",
    "explanation": "A cláusula 'LIMIT' é usada para especificar o número máximo de linhas que a consulta deve retornar."
  },
  {
    "question": "Qual é o papel do 'Cluster Mode' no Databricks?",
    "options": [
      "Determinar a interface do usuário",
      "Definir como o driver e os executores são alocados",
      "Especificar o sistema operacional",
      "Configurar a segurança do cluster"
    ],
    "answer": 1,
    "category": "Conceitos do Lakehouse",
    "explanation": "O 'Cluster Mode' determina a distribuição do driver e dos executores em um cluster de computação."
  },
  {
    "question": "O que é 'Data Lineage' em Data Governance?",
    "options": [
      "O histórico de origens e transformações dos dados",
      "A qualidade dos dados em um sistema",
      "A segurança aplicada aos dados",
      "A estrutura de armazenamento dos dados"
    ],
    "answer": 0,
    "category": "Data Governance",
    "explanation": "'Data Lineage' refere-se ao rastreamento da origem dos dados e todas as transformações que eles sofreram."
  },
  {
    "question": "What is 'Data Skew' in distributed data processing?",
    "options": [
      "When data is evenly distributed across partitions",
      "When a large portion of the data is concentrated in a few keys, causing performance issues",
      "When data is duplicated across nodes",
      "When data is encrypted"
    ],
    "answer": 1,
    "category": "Data Engineering",
    "explanation": "'Data Skew' occurs when some partitions process significantly more data than others, leading to an imbalance in processing."
  },
  {
    "question": "No Spark, o que é 'reduceByKey()'?",
    "options": [
      "Combinar valores com base em uma chave comum",
      "Filtrar dados duplicados",
      "Dividir dados em partições menores",
      "Classificar dados com base em uma chave"
    ],
    "answer": 0,
    "category": "Apache Spark",
    "explanation": "'reduceByKey()' é uma transformação no Spark que combina valores que compartilham a mesma chave usando uma função de redução."
  },
  {
    "question": "No Databricks, o que é 'Parquet'?",
    "options": [
      "Um formato de arquivo colunares otimizado",
      "Uma linguagem de programação",
      "Um tipo de cluster",
      "Uma ferramenta de visualização de dados"
    ],
    "answer": 0,
    "category": "Conceitos do Lakehouse",
    "explanation": "'Parquet' é um formato de arquivo colunares que é eficiente para armazenamento e processamento de dados analíticos."
  },
  {
    "question": "O que é 'Parquet' no contexto do Spark?",
    "options": [
      "Um formato de arquivo colunares eficiente para análises",
      "Um módulo de Machine Learning",
      "Uma ferramenta de visualização",
      "Um tipo de cluster"
    ],
    "answer": 0,
    "category": "Apache Spark",
    "explanation": "'Parquet' é um formato de arquivo colunares que oferece eficiência no armazenamento e processamento analítico de dados."
  },
  {
    "question": "Which SQL command is used to remove a column from a table?",
    "options": [
      "ALTER TABLE ... DROP COLUMN",
      "DELETE COLUMN",
      "REMOVE COLUMN",
      "ALTER COLUMN ... DELETE"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "The 'ALTER TABLE ... DROP COLUMN' command is used to remove a specific column from a table."
  },
  {
    "question": "What does 'Schema Evolution' in Delta Lake allow?",
    "options": [
      "Automatic schema updates as new data is ingested",
      "Data encryption during query execution",
      "Partitioning of data by columns",
      "Time travel queries"
    ],
    "answer": 0,
    "category": "Delta Lake",
    "explanation": "'Schema Evolution' allows Delta Lake tables to automatically update their schema as new data with different structures is added."
  },
  {
    "question": "O que é 'Cluster Manager' no Spark?",
    "options": [
      "Um componente que gerencia recursos e agendamento de tarefas",
      "Uma ferramenta de visualização de dados",
      "Um módulo para executar consultas SQL",
      "Um sistema de armazenamento de dados"
    ],
    "answer": 0,
    "category": "Apache Spark",
    "explanation": "O 'Cluster Manager' gerencia os recursos do cluster e agenda a execução de aplicativos Spark."
  },
  {
    "question": "No contexto do Databricks, o que é o 'Databricks Runtime'?",
    "options": [
      "Um sistema operacional personalizado",
      "Uma distribuição otimizada do Apache Spark",
      "Uma linguagem de programação proprietária",
      "Um banco de dados relacional"
    ],
    "answer": 1,
    "category": "Conceitos do Lakehouse",
    "explanation": "O Databricks Runtime é uma distribuição otimizada do Apache Spark que inclui melhorias de desempenho e funcionalidades adicionais."
  },
  {
    "question": "O que é 'Lazy Evaluation' no Spark?",
    "options": [
      "Executar operações imediatamente",
      "Executar operações somente quando necessário",
      "Otimizar consultas em tempo real",
      "Dividir dados em partições"
    ],
    "answer": 1,
    "category": "Apache Spark",
    "explanation": "'Lazy Evaluation' no Spark significa que as transformações não são executadas imediatamente, mas são adiadas até que uma ação seja chamada."
  },
  {
    "question": "What does 'Checkpointing' do in Spark Streaming?",
    "options": [
      "It optimizes data partitioning",
      "It saves the state of streaming data to ensure fault tolerance",
      "It reduces the size of data files",
      "It replicates data across nodes"
    ],
    "answer": 1,
    "category": "Streaming",
    "explanation": "'Checkpointing' in Spark Streaming saves the state of streaming jobs to disk, enabling recovery in case of failure."
  },
  {
    "question": "Which feature of Databricks clusters helps to scale resources automatically based on workload?",
    "options": [
      "Delta Lake",
      "Photon Engine",
      "Auto Scaling",
      "Job Scheduler"
    ],
    "answer": 2,
    "category": "Cluster Management",
    "explanation": "Auto Scaling adjusts the resources allocated to a Databricks cluster based on the workload, improving efficiency."
  },
  {
    "question": "O que é um 'Accumulator' no Spark?",
    "options": [
      "Uma variável somente leitura compartilhada entre executores",
      "Uma variável que permite operações de soma agregada",
      "Um módulo de cache de dados",
      "Uma função para criar DataFrames"
    ],
    "answer": 1,
    "category": "Apache Spark",
    "explanation": "Um 'Accumulator' é usado para realizar operações de agregação, como somas, de forma paralela entre os executores."
  },
  {
    "question": "No Databricks, o que são 'Global Temp Views'?",
    "options": [
      "Visualizações temporárias disponíveis apenas para a sessão atual",
      "Visualizações temporárias compartilhadas entre todas as sessões e clusters",
      "Tabelas permanentes armazenadas no sistema",
      "Visualizações usadas apenas para visualização de dados"
    ],
    "answer": 1,
    "category": "Databricks SQL",
    "explanation": "'Global Temp Views' são visualizações temporárias que podem ser acessadas por diferentes sessões e clusters."
  },
  {
    "question": "No Databricks, o que é 'Photon'?",
    "options": [
      "Um acelerador de consultas SQL de alto desempenho",
      "Uma linguagem de programação",
      "Um sistema de armazenamento de dados",
      "Um serviço de aprendizado de máquina"
    ],
    "answer": 0,
    "category": "Databricks SQL",
    "explanation": "O 'Photon' é um mecanismo nativo de execução de consultas SQL que oferece alto desempenho no Databricks."
  },
  {
    "question": "What is the role of Databricks Auto Scaling?",
    "options": [
      "Adjusting cluster size based on workload",
      "Preventing all downtime",
      "Only scaling up clusters",
      "Requires manual adjustments"
    ],
    "answer": 0,
    "category": "Cluster Management",
    "explanation": "Databricks Auto Scaling automatically adjusts the size of a cluster based on the workload to optimize resource usage."
  },
  {
    "question": "Qual comando SQL é usado para criar um índice em uma tabela?",
    "options": [
      "CREATE INDEX",
      "ADD INDEX",
      "GENERATE INDEX",
      "MAKE INDEX"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "O comando 'CREATE INDEX' é usado para criar um índice em uma ou mais colunas de uma tabela."
  },
  {
    "question": "Which Databricks feature provides high-performance query execution for SQL workloads?",
    "options": [
      "Photon Engine",
      "Delta Live Tables",
      "Auto Scaling",
      "MLflow"
    ],
    "answer": 0,
    "category": "Databricks SQL",
    "explanation": "Photon Engine is a high-performance query execution engine optimized for running SQL workloads in Databricks."
  },
  {
    "question": "What does the 'ORDER BY' clause do in SQL?",
    "options": [
      "Filters data based on conditions",
      "Groups records based on values",
      "Limits the number of returned rows",
      "Sorts the results of a query"
    ],
    "answer": 3,
    "category": "SQL",
    "explanation": "'ORDER BY' is used to sort the result set in either ascending or descending order based on one or more columns."
  },
  {
    "question": "O que é 'Schema Enforcement' no Delta Lake?",
    "options": [
      "Permitir qualquer tipo de dados sem restrições",
      "Garantir que os dados escritos correspondam ao esquema definido",
      "Atualizar automaticamente o esquema com base nos dados",
      "Remover colunas não utilizadas"
    ],
    "answer": 1,
    "category": "Delta Lake",
    "explanation": "'Schema Enforcement' assegura que apenas dados compatíveis com o esquema definido sejam gravados na tabela Delta."
  },
  {
    "question": "O que é 'Pipeline de Dados' em Data Engineering?",
    "options": [
      "Uma sequência de etapas de processamento de dados",
      "Um tipo de banco de dados relacional",
      "Uma ferramenta de visualização de dados",
      "Um método de compactação de dados"
    ],
    "answer": 0,
    "category": "Data Engineering",
    "explanation": "Um 'Pipeline de Dados' é um conjunto de processos que extrai, transforma e carrega dados de uma fonte para um destino."
  },
  {
    "question": "O que é 'DataFrame API' no Spark?",
    "options": [
      "Uma interface para manipulação de dados estruturados",
      "Uma ferramenta de visualização de dados",
      "Um módulo de segurança",
      "Uma linguagem de programação proprietária"
    ],
    "answer": 0,
    "category": "Apache Spark",
    "explanation": "A 'DataFrame API' permite manipular dados estruturados de forma eficiente, semelhante a tabelas em bancos de dados."
  },
  {
    "question": "Which Databricks feature enables collaboration on notebooks in real-time?",
    "options": [
      "MLflow",
      "Delta Lake",
      "Real-Time Collaboration",
      "Git Integration"
    ],
    "answer": 2,
    "category": "Databricks Notebooks",
    "explanation": "Databricks supports real-time collaboration on notebooks, allowing multiple users to work on the same notebook simultaneously."
  },
  {
    "question": "Qual das seguintes opções NÃO é um tipo de join no SQL?",
    "options": [
      "INNER JOIN",
      "OUTER JOIN",
      "CROSS JOIN",
      "UPPER JOIN"
    ],
    "answer": 3,
    "category": "SQL",
    "explanation": "Não existe um 'UPPER JOIN' no SQL; os joins comuns são INNER, OUTER, LEFT, RIGHT e CROSS JOIN."
  },
  {
    "question": "Which SQL function is used to find the maximum value in a column?",
    "options": [
      "MAX()",
      "MIN()",
      "SUM()",
      "AVG()"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "The 'MAX()' function returns the largest value from a specified column."
  },
  {
    "question": "Qual é a finalidade da função 'SUBSTRING()' no SQL?",
    "options": [
      "Converter texto para maiúsculas",
      "Extrair uma parte de uma string",
      "Substituir caracteres em uma string",
      "Concatenar duas strings"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "A função 'SUBSTRING()' é usada para extrair uma porção específica de uma string com base em posição e comprimento."
  },
  {
    "question": "Qual é a função da cláusula 'ORDER BY' no SQL?",
    "options": [
      "Agrupar registros com valores idênticos",
      "Filtrar resultados após uma agregação",
      "Ordenar os resultados de uma consulta",
      "Limitar o número de resultados retornados"
    ],
    "answer": 2,
    "category": "SQL",
    "explanation": "A cláusula 'ORDER BY' é usada para ordenar os resultados de uma consulta em ordem ascendente ou descendente."
  },
  {
    "question": "In SQL, what is the function of the 'HAVING' clause?",
    "options": [
      "To filter rows before aggregation",
      "To limit the number of rows returned",
      "To filter rows after aggregation",
      "To order the results"
    ],
    "answer": 2,
    "category": "SQL",
    "explanation": "The 'HAVING' clause is used to filter records after aggregation has been performed."
  },
  {
    "question": "Which function in SQL is used to calculate the average of values in a column?",
    "options": [
      "SUM()",
      "AVG()",
      "COUNT()",
      "MIN()"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "The 'AVG()' function returns the average of the values in a numeric column."
  },
  {
    "question": "Qual é o propósito do comando 'REVOKE' no SQL?",
    "options": [
      "Conceder permissões a um usuário",
      "Remover permissões de um usuário",
      "Atualizar dados em uma tabela",
      "Criar um novo banco de dados"
    ],
    "answer": 1,
    "category": "Data Governance",
    "explanation": "O 'REVOKE' é usado para remover permissões previamente concedidas a um usuário ou role."
  },
  {
    "question": "O que é 'Pipeline de Dados' no Databricks?",
    "options": [
      "Um modelo de Machine Learning",
      "Uma sequência de etapas para ingestão, processamento e saída de dados",
      "Uma técnica de otimização de consultas",
      "Um sistema de armazenamento de dados"
    ],
    "answer": 1,
    "category": "Data Engineering",
    "explanation": "'Pipeline de Dados' é uma sequência de operações que extrai, transforma e carrega dados em um sistema."
  },
  {
    "question": "O que é 'Structured Streaming' no Spark?",
    "options": [
      "Uma API para processamento de fluxos de dados em tempo real",
      "Uma ferramenta de agendamento de tarefas",
      "Um módulo para análise de dados estruturados",
      "Uma biblioteca de visualização"
    ],
    "answer": 0,
    "category": "Streaming",
    "explanation": "O 'Structured Streaming' é uma API que permite o processamento de fluxos de dados de forma contínua e escalável."
  },
  {
    "question": "No Databricks, qual é a função do 'Job Scheduler'?",
    "options": [
      "Agendar e gerenciar a execução de jobs",
      "Visualizar dados em tempo real",
      "Gerenciar permissões de usuário",
      "Criar clusters de computação"
    ],
    "answer": 0,
    "category": "Conceitos do Lakehouse",
    "explanation": "O 'Job Scheduler' permite agendar e monitorar a execução de jobs, como notebooks ou scripts."
  },
  {
    "question": "O que é 'Catalyst Optimizer' no Spark SQL?",
    "options": [
      "Um módulo para visualizar dados",
      "O mecanismo de otimização de consultas do Spark SQL",
      "Um componente para gerenciamento de clusters",
      "Uma ferramenta de segurança"
    ],
    "answer": 1,
    "category": "Apache Spark",
    "explanation": "O 'Catalyst Optimizer' é o mecanismo interno do Spark SQL que otimiza o plano de execução de consultas."
  },
  {
    "question": "O que é 'Caching' no contexto do Spark?",
    "options": [
      "Armazenar dados em memória para acesso rápido",
      "Excluir dados não utilizados",
      "Compactar arquivos de dados",
      "Dividir dados em partições"
    ],
    "answer": 0,
    "category": "Conceitos do Lakehouse",
    "explanation": "O 'Caching' armazena dados frequentemente acessados em memória para melhorar o desempenho das consultas."
  },
  {
    "question": "In Apache Spark, what is the function of 'Broadcast Join'?",
    "options": [
      "A join operation that replicates a small table to all nodes",
      "A join operation that distributes data evenly across nodes",
      "A join that only works with streaming data",
      "A join that filters out duplicate records"
    ],
    "answer": 0,
    "category": "Apache Spark",
    "explanation": "'Broadcast Join' in Spark replicates a small dataset to all nodes to optimize joins with large datasets."
  },
  {
    "question": "No Databricks, qual recurso permite versionar código dentro de notebooks?",
    "options": [
      "Notebook Revisions",
      "Git Integration",
      "Cluster Snapshots",
      "Version Control System"
    ],
    "answer": 1,
    "category": "Conceitos do Lakehouse",
    "explanation": "A integração com Git permite versionar e controlar o código dentro dos notebooks do Databricks."
  },
  {
    "question": "What is the purpose of the 'EXPLAIN' command in SQL?",
    "options": [
      "To execute a query",
      "To provide the execution plan of a query",
      "To update records in a table",
      "To delete a table"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "The 'EXPLAIN' command in SQL is used to display the execution plan for a query."
  },
  {
    "question": "No Databricks, qual é a vantagem de usar 'Tables ACID'?",
    "options": [
      "Melhora a compressão de dados",
      "Suporta transações com propriedades ACID",
      "Facilita a criação de visualizações",
      "Permite consultas em linguagem natural"
    ],
    "answer": 1,
    "category": "Delta Lake",
    "explanation": "Tabelas ACID garantem Atomicidade, Consistência, Isolamento e Durabilidade nas transações de dados."
  },
  {
    "question": "Which of the following statements is true about Delta Lake's schema enforcement?",
    "options": [
      "It prevents invalid data from being written",
      "It allows any data format",
      "It enforces schema only at the database level",
      "It cannot be modified after table creation"
    ],
    "answer": 0,
    "category": "Delta Lake",
    "explanation": "Schema enforcement in Delta Lake ensures that only data that matches the table's schema can be written to the table."
  },
  {
    "question": "What type of consistency does Delta Lake offer?",
    "options": [
      "Eventual consistency",
      "Strong consistency",
      "No consistency",
      "Weak consistency"
    ],
    "answer": 1,
    "category": "Delta Lake",
    "explanation": "Delta Lake provides strong consistency, meaning that once a transaction is committed, all subsequent queries will see the result."
  },
  {
    "question": "Which Databricks feature enables real-time stream processing?",
    "options": [
      "Delta Lake",
      "Structured Streaming",
      "Photon Engine",
      "SQL Analytics"
    ],
    "answer": 1,
    "category": "Real-Time Processing",
    "explanation": "Structured Streaming allows real-time stream processing of data in Databricks."
  },
  {
    "question": "What does 'Lazy Evaluation' mean in Apache Spark?",
    "options": [
      "Operations are executed immediately",
      "Operations are delayed until an action is triggered",
      "Operations are optimized in real-time",
      "Data is split into partitions"
    ],
    "answer": 1,
    "category": "Apache Spark",
    "explanation": "In Spark, 'Lazy Evaluation' means that transformations are not executed until an action is called."
  },
  {
    "question": "What is the primary purpose of the 'GRANT' command in SQL?",
    "options": [
      "To update records",
      "To create a new table",
      "To provide permissions to a user",
      "To delete a database"
    ],
    "answer": 2,
    "category": "Data Governance",
    "explanation": "The 'GRANT' command is used to provide specific permissions to a user or role in SQL."
  },
  {
    "question": "Qual é a função do comando 'DESCRIBE TABLE' no SQL?",
    "options": [
      "Inserir dados em uma tabela",
      "Mostrar a estrutura de uma tabela",
      "Excluir uma tabela",
      "Atualizar registros em uma tabela"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "O comando 'DESCRIBE TABLE' é usado para exibir a estrutura e os detalhes de uma tabela, como colunas e tipos de dados."
  },
  {
    "question": "Which Delta Lake feature supports querying of older versions of data?",
    "options": [
      "Z-Ordering",
      "Data Skew",
      "Schema Evolution",
      "Time Travel"
    ],
    "answer": 3,
    "category": "Delta Lake",
    "explanation": "'Time Travel' allows users to query earlier versions of data for auditing or rollback purposes."
  },
  {
    "question": "What is the main advantage of using 'Photon' in Databricks?",
    "options": [
      "Improves query performance",
      "Enhances data security",
      "Simplifies machine learning model training",
      "Automates cluster scaling"
    ],
    "answer": 0,
    "category": "Databricks SQL",
    "explanation": "Photon is a high-performance query execution engine in Databricks, designed to improve SQL query performance."
  },
  {
    "question": "Qual é a finalidade do comando 'GRANT' no SQL?",
    "options": [
      "Remover permissões de um usuário",
      "Conceder permissões a um usuário",
      "Criar um novo banco de dados",
      "Atualizar registros em uma tabela"
    ],
    "answer": 1,
    "category": "Data Governance",
    "explanation": "O comando 'GRANT' é usado para conceder permissões específicas a usuários ou roles em objetos de banco de dados."
  },
  {
    "question": "Qual é a finalidade da função 'COUNT()' no SQL?",
    "options": [
      "Somar todos os valores de uma coluna",
      "Contar o número de linhas em uma tabela ou resultado de consulta",
      "Encontrar o valor mínimo em uma coluna",
      "Calcular a média dos valores em uma coluna"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "A função 'COUNT()' retorna o número de linhas que correspondem a um critério específico."
  },
  {
    "question": "Qual comando SQL é usado para criar uma visão virtual de uma consulta?",
    "options": [
      "CREATE VIEW",
      "CREATE TABLE",
      "CREATE INDEX",
      "CREATE PROCEDURE"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "O comando 'CREATE VIEW' é usado para criar uma visão virtual com base nos resultados de uma consulta SQL."
  },
  {
    "question": "Qual é a finalidade do comando 'EXPLAIN' no SQL?",
    "options": [
      "Executar uma consulta",
      "Fornecer o plano de execução de uma consulta",
      "Atualizar dados em uma tabela",
      "Criar uma nova tabela"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "O comando 'EXPLAIN' mostra o plano de execução que o banco de dados usará para executar uma consulta."
  },
  {
    "question": "In Databricks, what is the 'Job Scheduler' used for?",
    "options": [
      "To create real-time pipelines",
      "To manage permissions",
      "To schedule and manage job executions",
      "To configure cluster settings"
    ],
    "answer": 2,
    "category": "Job Management",
    "explanation": "The 'Job Scheduler' in Databricks allows users to schedule jobs, including notebooks, to run at specified intervals."
  },
  {
    "question": "O que é 'Repartition' no Spark?",
    "options": [
      "Combinar várias partições em uma",
      "Aumentar ou diminuir o número de partições de um RDD ou DataFrame",
      "Ordenar os dados dentro de uma partição",
      "Filtrar dados em uma partição específica"
    ],
    "answer": 1,
    "category": "Apache Spark",
    "explanation": "A operação 'Repartition' altera o número de partições de um RDD ou DataFrame, o que pode ajudar no balanceamento de carga."
  },
  {
    "question": "Qual é a finalidade do comando 'ALTER TABLE ... RENAME COLUMN' no SQL?",
    "options": [
      "Alterar o tipo de dados de uma coluna",
      "Renomear uma coluna existente em uma tabela",
      "Adicionar uma nova coluna a uma tabela",
      "Excluir uma coluna de uma tabela"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "O comando 'ALTER TABLE ... RENAME COLUMN' é usado para renomear uma coluna existente em uma tabela."
  },
  {
    "question": "O que é 'Databricks File System' (DBFS)?",
    "options": [
      "Um sistema de arquivos distribuído",
      "Uma interface de linha de comando",
      "Uma biblioteca de Machine Learning",
      "Um banco de dados relacional"
    ],
    "answer": 0,
    "category": "Conceitos do Lakehouse",
    "explanation": "O DBFS é um sistema de arquivos distribuído que permite o acesso a dados armazenados em nuvem como se fossem locais."
  },
  {
    "question": "Qual comando SQL é usado para inserir novos dados em uma tabela?",
    "options": [
      "INSERT INTO",
      "ADD DATA",
      "UPDATE TABLE",
      "APPEND ROW"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "O comando 'INSERT INTO' é usado para adicionar novos registros a uma tabela existente."
  },
  {
    "question": "O que significa ETL em Data Engineering?",
    "options": [
      "Extract, Transform, Load",
      "Evaluate, Test, Launch",
      "Edit, Transfer, Link",
      "Encrypt, Transfer, Log"
    ],
    "answer": 0,
    "category": "Data Engineering",
    "explanation": "ETL significa 'Extract, Transform, Load', que são as etapas para mover e transformar dados entre sistemas."
  },
  {
    "question": "No contexto do Apache Spark, o que é 'Broadcast Join'?",
    "options": [
      "Um join que replica uma pequena tabela para todos os nós",
      "Um join que distribui dados igualmente entre nós",
      "Um join que só funciona com dados de streaming",
      "Um join que ignora dados duplicados"
    ],
    "answer": 0,
    "category": "Apache Spark",
    "explanation": "'Broadcast Join' é uma técnica onde uma pequena tabela é enviada para todos os nós para otimizar o join com uma tabela grande."
  },
  {
    "question": "O que é 'Data Partitioning' no Spark?",
    "options": [
      "Dividir os dados em partes para processamento paralelo",
      "Compactar dados para economizar espaço",
      "Combinar múltiplos datasets",
      "Transformar dados em formato binário"
    ],
    "answer": 0,
    "category": "Apache Spark",
    "explanation": "O 'Data Partitioning' divide os dados em partições menores para que possam ser processados em paralelo pelos executores do Spark."
  },
  {
    "question": "No contexto de visualização de dados, o que é um 'Heatmap'?",
    "options": [
      "Um gráfico que mostra a distribuição de dados geográficos",
      "Uma representação gráfica que usa cores para mostrar a magnitude dos valores",
      "Um gráfico que conecta pontos de dados em uma linha",
      "Um tipo de gráfico de barras vertical"
    ],
    "answer": 1,
    "category": "Visualização de Dados",
    "explanation": "Um 'Heatmap' usa cores para representar a magnitude dos valores em uma matriz bidimensional."
  },
  {
    "question": "No Spark, o que é uma 'Wide Transformation'?",
    "options": [
      "Uma transformação que afeta apenas uma partição",
      "Uma transformação que requer 'shuffling' dos dados entre executores",
      "Uma transformação que reduz o número de partições",
      "Uma transformação que aumenta o paralelismo"
    ],
    "answer": 1,
    "category": "Apache Spark",
    "explanation": "Uma 'Wide Transformation' envolve operações que requerem 'shuffling', redistribuindo dados entre partições e executores."
  },
  {
    "question": "Qual é a função da operação 'map()' no Spark?",
    "options": [
      "Combinar múltiplos RDDs em um",
      "Aplicar uma função a cada elemento de um RDD",
      "Ordenar dados dentro de uma partição",
      "Executar uma ação no driver"
    ],
    "answer": 1,
    "category": "Apache Spark",
    "explanation": "A função 'map()' aplica uma função especificada a cada elemento de um RDD ou DataFrame no Spark."
  },
  {
    "question": "No contexto do Spark, o que é 'Broadcast Variable'?",
    "options": [
      "Uma variável compartilhada enviada a todos os executores",
      "Uma variável que muda frequentemente durante a execução",
      "Uma variável usada apenas pelo driver",
      "Uma variável que armazena logs"
    ],
    "answer": 0,
    "category": "Apache Spark",
    "explanation": "Uma 'Broadcast Variable' é uma variável imutável que é distribuída para todos os executores para uso eficiente."
  },
  {
    "question": "In Databricks, what is the purpose of a 'Job Cluster'?",
    "options": [
      "To store data",
      "To run scheduled jobs and terminate automatically after completion",
      "To execute interactive queries",
      "To manage user permissions"
    ],
    "answer": 1,
    "category": "Cluster Management",
    "explanation": "A 'Job Cluster' in Databricks is created to run a job and is terminated once the job is completed."
  },
  {
    "question": "Which Databricks feature helps to optimize queries for faster performance?",
    "options": [
      "Databricks Photon",
      "MLflow",
      "Delta Live Tables",
      "SQL Analytics"
    ],
    "answer": 0,
    "category": "Optimization",
    "explanation": "Databricks Photon is a vectorized engine that optimizes query execution for faster performance."
  },
  {
    "question": "What is the main benefit of Z-Ordering in Delta Lake?",
    "options": [
      "It compresses data for faster queries",
      "It organizes data to improve query performance",
      "It provides data encryption",
      "It enables time travel"
    ],
    "answer": 1,
    "category": "Delta Lake",
    "explanation": "Z-Ordering optimizes the physical layout of data to improve the performance of queries that filter on specific columns."
  },
  {
    "question": "No Databricks, qual recurso permite o processamento em tempo real de dados de streaming?",
    "options": [
      "Delta Engine",
      "Structured Streaming",
      "Auto Loader",
      "Time Travel"
    ],
    "answer": 1,
    "category": "Streaming",
    "explanation": "O Structured Streaming é a API do Spark para processar fluxos de dados em tempo real no Databricks."
  },
  {
    "question": "Qual comando SQL é usado para remover uma coluna de uma tabela?",
    "options": [
      "DELETE COLUMN",
      "REMOVE COLUMN",
      "ALTER TABLE ... DROP COLUMN",
      "DROP COLUMN FROM TABLE"
    ],
    "answer": 2,
    "category": "SQL",
    "explanation": "O comando 'ALTER TABLE ... DROP COLUMN' é usado para remover uma coluna específica de uma tabela existente."
  },
  {
    "question": "Which command in SQL is used to remove all rows from a table while keeping the structure?",
    "options": [
      "DELETE",
      "TRUNCATE",
      "DROP",
      "REMOVE"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "The TRUNCATE command deletes all rows from a table but retains its structure for future data insertion."
  },
  {
    "question": "Qual comando SQL é usado para conceder todas as permissões em um objeto a um usuário?",
    "options": [
      "GRANT ALL PRIVILEGES ON objeto TO usuário",
      "GRANT FULL ACCESS ON objeto TO usuário",
      "GRANT PERMISSIONS ON objeto TO usuário",
      "GRANT ACCESS ON objeto TO usuário"
    ],
    "answer": 0,
    "category": "Data Governance",
    "explanation": "O comando 'GRANT ALL PRIVILEGES ON objeto TO usuário' concede todas as permissões disponíveis no objeto especificado."
  },
  {
    "question": "What is the function of the 'Spark UI' in Databricks?",
    "options": [
      "To visualize datasets",
      "To manage job scheduling",
      "To monitor job execution and performance",
      "To update cluster settings"
    ],
    "answer": 2,
    "category": "Monitoring",
    "explanation": "The 'Spark UI' allows users to monitor job execution, track performance, and troubleshoot issues in Spark jobs."
  },
  {
    "question": "Qual é a finalidade da função 'CAST()' no SQL?",
    "options": [
      "Converter um valor de um tipo de dados para outro",
      "Remover espaços em branco de uma string",
      "Combinar duas ou mais strings",
      "Gerar números aleatórios"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "A função 'CAST()' é usada para converter expressões de um tipo de dados para outro."
  },
  {
    "question": "No contexto do Spark, o que é um 'Resilient Distributed Dataset' (RDD)?",
    "options": [
      "Uma coleção imutável de objetos distribuídos",
      "Um tipo de banco de dados relacional",
      "Uma função para processamento de streams",
      "Um mecanismo de armazenamento em cache"
    ],
    "answer": 0,
    "category": "Apache Spark",
    "explanation": "Um RDD é uma coleção distribuída e imutável de objetos que podem ser processados em paralelo."
  },
  {
    "question": "O que é uma 'View' no contexto de bancos de dados SQL?",
    "options": [
      "Uma cópia física de uma tabela",
      "Uma tabela temporária que armazena dados",
      "Uma consulta armazenada que se comporta como uma tabela",
      "Um índice para acelerar consultas"
    ],
    "answer": 2,
    "category": "SQL",
    "explanation": "Uma View é uma consulta armazenada no banco de dados que pode ser tratada como uma tabela virtual."
  },
  {
    "question": "O que é 'Lazy Evaluation' no contexto do Spark?",
    "options": [
      "Execução imediata de todas as operações",
      "Adiar a execução até que seja necessária",
      "Um método de otimização de memória",
      "Uma técnica para limpar dados"
    ],
    "answer": 1,
    "category": "Apache Spark",
    "explanation": "'Lazy Evaluation' significa que o Spark adia a execução das operações até que uma ação seja chamada."
  },
  {
    "question": "What does the 'EXPLAIN' command in SQL do?",
    "options": [
      "It provides the execution plan for a query",
      "It updates records in a table",
      "It creates a new table",
      "It deletes all rows in a table"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "The 'EXPLAIN' command shows the execution plan that the SQL engine will use to run a query."
  },
  {
    "question": "What does the 'DROP TABLE' command do in SQL?",
    "options": [
      "Deletes all rows in a table",
      "Removes a table from the database",
      "Deletes duplicate records",
      "Creates a new empty table"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "The 'DROP TABLE' command deletes a table and all its data from the database."
  },
  {
    "question": "O que é 'Spark SQL' no contexto do Databricks?",
    "options": [
      "Uma interface para interagir com o Spark usando SQL",
      "Um banco de dados interno do Spark",
      "Uma ferramenta para visualização de dados",
      "Um módulo de Machine Learning"
    ],
    "answer": 0,
    "category": "Databricks SQL",
    "explanation": "O Spark SQL permite que os usuários executem consultas SQL sobre dados armazenados no Apache Spark."
  },
  {
    "question": "Qual comando SQL é usado para alterar o nome de uma tabela existente?",
    "options": [
      "ALTER TABLE ... RENAME TO",
      "UPDATE TABLE ... SET NAME",
      "RENAME TABLE ... TO",
      "CHANGE TABLE NAME TO"
    ],
    "answer": 0,
    "category": "SQL",
    "explanation": "O comando 'ALTER TABLE ... RENAME TO' é usado para renomear uma tabela existente no SQL."
  },
  {
    "question": "Qual é a finalidade do comando 'USE DATABASE' no SQL?",
    "options": [
      "Criar um novo banco de dados",
      "Selecionar um banco de dados para uso",
      "Excluir um banco de dados",
      "Atualizar registros em um banco de dados"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "O comando 'USE DATABASE' seleciona um banco de dados específico para que as operações subsequentes sejam executadas nele."
  },
  {
    "question": "Which tool in Databricks helps to monitor the performance and execution of jobs?",
    "options": [
      "Job UI",
      "Structured Streaming",
      "Spark UI",
      "MLflow"
    ],
    "answer": 2,
    "category": "Monitoring",
    "explanation": "The Spark UI allows you to monitor the execution of Spark jobs and diagnose performance issues."
  },
  {
    "question": "O que é 'Schema Evolution' no Delta Lake?",
    "options": [
      "A capacidade de alterar o esquema de dados ao longo do tempo",
      "Uma técnica de otimização de consultas",
      "Um método de particionamento de dados",
      "Uma ferramenta de segurança de dados"
    ],
    "answer": 0,
    "category": "Delta Lake",
    "explanation": "O 'Schema Evolution' permite que o esquema de uma tabela Delta seja alterado automaticamente para acomodar novos dados."
  },
  {
    "question": "O que é 'Delta Lake Z-Ordering'?",
    "options": [
      "Um método de compactação de arquivos",
      "Uma técnica de otimização que organiza os dados para melhorar o desempenho de consultas",
      "Uma função de segurança",
      "Um tipo de armazenamento em nuvem"
    ],
    "answer": 1,
    "category": "Delta Lake",
    "explanation": "'Z-Ordering' é uma técnica que ordena dados em colunas especificadas para otimizar o desempenho de consultas no Delta Lake."
  },
  {
    "question": "Which feature in Databricks simplifies the creation of real-time data pipelines?",
    "options": [
      "Photon Engine",
      "Delta Live Tables",
      "Job Scheduler",
      "Cluster Manager"
    ],
    "answer": 1,
    "category": "Real-Time Processing",
    "explanation": "Delta Live Tables simplifies real-time analytics pipelines by automating data ingestion, transformation, and validation."
  },
  {
    "question": "No Databricks, o que é um 'Interactive Cluster'?",
    "options": [
      "Um cluster usado para executar jobs agendados",
      "Um cluster que permite desenvolvimento e análise interativos",
      "Um cluster que é sempre executado em segundo plano",
      "Um cluster utilizado apenas para armazenamento de dados"
    ],
    "answer": 1,
    "category": "Cluster Management",
    "explanation": "Um 'Interactive Cluster' é usado para desenvolvimento interativo, permitindo que os usuários executem comandos e vejam resultados imediatamente."
  },
  {
    "question": "Qual é a diferença entre 'DataFrame' e 'Dataset' no Spark?",
    "options": [
      "DataFrames são não tipados, Datasets são tipados",
      "Datasets são não tipados, DataFrames são tipados",
      "Não há diferença",
      "Datasets só suportam linguagem SQL"
    ],
    "answer": 0,
    "category": "Apache Spark",
    "explanation": "DataFrames não possuem tipagem forte e são como Datasets de Row; Datasets adicionam tipagem forte usando objetos Java/Scala."
  },
  {
    "question": "No contexto do Spark, o que é uma 'Transformation'?",
    "options": [
      "Uma operação que retorna um valor ao driver",
      "Uma operação que cria um novo RDD a partir de um existente",
      "Um método para definir esquemas",
      "Uma ferramenta de visualização"
    ],
    "answer": 1,
    "category": "Apache Spark",
    "explanation": "Uma 'Transformation' cria um novo RDD a partir de um existente, aplicando uma função de transformação."
  },
  {
    "question": "Which Databricks feature automatically adjusts the size of a cluster based on workload?",
    "options": [
      "Time Travel",
      "Auto Loader",
      "Cluster Auto-scaling",
      "Photon Engine"
    ],
    "answer": 2,
    "category": "Cluster Management",
    "explanation": "Cluster Auto-scaling automatically increases or decreases the number of nodes in a cluster based on workload."
  },
  {
    "question": "What is the primary benefit of using Delta Lake?",
    "options": [
      "Creating visualizations",
      "Supporting ACID transactions",
      "Training machine learning models",
      "Integrating with external databases"
    ],
    "answer": 1,
    "category": "Delta Lake",
    "explanation": "Delta Lake supports ACID transactions, ensuring data consistency and reliability."
  },
  {
    "question": "Which SQL clause is used to filter data after aggregation?",
    "options": [
      "GROUP BY",
      "ORDER BY",
      "HAVING",
      "LIMIT"
    ],
    "answer": 2,
    "category": "SQL",
    "explanation": "'HAVING' is used to filter data after an aggregation has been performed, such as with GROUP BY."
  },
  {
    "question": "Which of the following is a benefit of Delta Lake's 'Time Travel' feature?",
    "options": [
      "Data encryption",
      "Query optimization",
      "Querying older versions of data",
      "Partitioning data"
    ],
    "answer": 2,
    "category": "Delta Lake",
    "explanation": "'Time Travel' in Delta Lake allows users to access previous versions of data for auditing or rollback."
  },
  {
    "question": "Qual é a finalidade do comando 'TRUNCATE TABLE' no SQL?",
    "options": [
      "Excluir uma tabela",
      "Remover todas as linhas de uma tabela",
      "Atualizar registros específicos",
      "Reduzir o tamanho físico da tabela"
    ],
    "answer": 1,
    "category": "SQL",
    "explanation": "O 'TRUNCATE TABLE' remove todas as linhas de uma tabela de forma eficiente, mas mantém sua estrutura."
  },
  {
    "question": "What does 'Z-Ordering' in Delta Lake optimize?",
    "options": [
      "Data encryption",
      "Query performance for specific columns",
      "Machine learning model training",
      "Data insertion speed"
    ],
    "answer": 1,
    "category": "Delta Lake",
    "explanation": "'Z-Ordering' improves query performance by physically reorganizing data for more efficient access to specific columns."
  },
  {
    "question": "No Databricks, o que é 'DBFS Fuse'?",
    "options": [
      "Um sistema de arquivos virtual que permite acessar o DBFS localmente",
      "Uma ferramenta de segurança de arquivos",
      "Um formato de arquivo proprietário",
      "Um módulo para streaming de dados"
    ],
    "answer": 0,
    "category": "Conceitos do Lakehouse",
    "explanation": "'DBFS Fuse' permite montar o Databricks File System (DBFS) em sistemas locais, tornando os arquivos acessíveis via comandos do sistema operacional."
  },
  {
    "question": "What does the 'OPTIMIZE' command do in Delta Lake?",
    "options": [
      "Increases query performance by organizing data files",
      "Deletes old versions of data",
      "Adds new data to a table",
      "Reverts to previous table versions"
    ],
    "answer": 0,
    "category": "Delta Lake",
    "explanation": "The 'OPTIMIZE' command improves query performance by compacting small data files into larger, more efficient ones."
  },
  {
    "question": "No Databricks, qual é o propósito do 'Cluster Manager'?",
    "options": [
      "Gerenciar recursos computacionais",
      "Criar visualizações de dados",
      "Escrever código SQL",
      "Armazenar dados em tabelas"
    ],
    "answer": 0,
    "category": "Conceitos do Lakehouse",
    "explanation": "O 'Cluster Manager' é responsável por gerenciar a criação e operação de clusters de computação."
  },
  {
    "question": "What does 'Lazy Evaluation' in Spark mean?",
    "options": [
      "Transformations are executed immediately",
      "Actions are delayed until triggered by a transformation",
      "Transformations are delayed until an action is called",
      "Data is split into multiple partitions"
    ],
    "answer": 2,
    "category": "Apache Spark",
    "explanation": "'Lazy Evaluation' means that transformations in Spark are not executed until an action is called, optimizing performance."
  },
  {
    "question": "Which feature allows Databricks users to track and manage machine learning models?",
    "options": [
      "SQL Analytics",
      "MLflow",
      "Delta Live Tables",
      "Spark SQL"
    ],
    "answer": 1,
    "category": "Machine Learning",
    "explanation": "MLflow is a tool in Databricks that allows users to track, manage, and deploy machine learning models."
  }
]